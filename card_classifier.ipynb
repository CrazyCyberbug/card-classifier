{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installing the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow tensorflow-gpu opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow_gpu-2.10.1-cp38-cp38-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu) (21.3)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp38-cp38-win_amd64.whl (896 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 3.8 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.50.0-cp38-cp38-win_amd64.whl (3.7 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "     ---------------------------------------- 5.9/5.9 MB 4.9 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.7.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu) (1.22.2)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "     -------------------------------------- 438.7/438.7 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.28.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu) (41.2.0)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "     -------------------------------------- 175.4/175.4 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.3/93.3 kB 5.5 MB/s eta 0:00:00\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     -------------------------------------- 781.3/781.3 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.28.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "     -------------------------------------- 232.7/232.7 kB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging->tensorflow-gpu) (3.0.7)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     -------------------------------------- 155.3/155.3 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.9.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, absl-py, requests-oauthlib, markdown, google-auth, astunparse, google-auth-oauthlib, tensorboard, tensorflow-gpu\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.10.26 gast-0.4.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.50.0 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-estimator-2.10.0 tensorflow-gpu-2.10.1 tensorflow-io-gcs-filesystem-0.28.0 termcolor-2.1.1 werkzeug-2.2.2 wheel-0.38.4 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of all the installed packages in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      1.3.0\n",
      "anyio                        3.6.1\n",
      "argon2-cffi                  21.3.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "asgiref                      3.5.2\n",
      "asttokens                    2.0.8\n",
      "astunparse                   1.6.3\n",
      "async-generator              1.10\n",
      "attrs                        22.1.0\n",
      "Babel                        2.10.3\n",
      "backcall                     0.2.0\n",
      "backports.zoneinfo           0.2.1\n",
      "beautifulsoup4               4.11.1\n",
      "bleach                       5.0.1\n",
      "cachetools                   5.2.0\n",
      "caer                         2.0.8\n",
      "certifi                      2022.9.24\n",
      "cffi                         1.15.1\n",
      "charset-normalizer           2.1.1\n",
      "colorama                     0.4.5\n",
      "cycler                       0.11.0\n",
      "debugpy                      1.6.3\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "Django                       4.1.2\n",
      "entrypoints                  0.4\n",
      "exceptiongroup               1.0.0rc9\n",
      "executing                    1.1.1\n",
      "facebook-sdk                 3.1.0\n",
      "fastjsonschema               2.16.2\n",
      "flatbuffers                  22.10.26\n",
      "fonttools                    4.30.0\n",
      "gast                         0.4.0\n",
      "google-auth                  2.14.1\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.50.0\n",
      "h11                          0.14.0\n",
      "h5py                         3.7.0\n",
      "idna                         3.4\n",
      "importlib-metadata           5.0.0\n",
      "importlib-resources          5.10.0\n",
      "ipykernel                    6.16.0\n",
      "ipython                      8.5.0\n",
      "ipython-genutils             0.2.0\n",
      "jedi                         0.18.1\n",
      "Jinja2                       3.1.2\n",
      "joblib                       1.2.0\n",
      "json5                        0.9.10\n",
      "jsonpickle                   2.2.0\n",
      "jsonschema                   4.16.0\n",
      "jupyter_client               7.4.2\n",
      "jupyter-core                 4.11.1\n",
      "jupyter-server               1.21.0\n",
      "jupyterlab                   3.4.8\n",
      "jupyterlab-pygments          0.2.2\n",
      "jupyterlab_server            2.16.0\n",
      "keras                        2.10.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.4.0\n",
      "libclang                     14.0.6\n",
      "Markdown                     3.4.1\n",
      "MarkupSafe                   2.1.1\n",
      "matplotlib                   3.5.1\n",
      "matplotlib-inline            0.1.6\n",
      "mistune                      2.0.4\n",
      "mypy                         0.931\n",
      "mypy-extensions              0.4.3\n",
      "nbclassic                    0.4.5\n",
      "nbclient                     0.7.0\n",
      "nbconvert                    7.2.1\n",
      "nbformat                     5.7.0\n",
      "nest-asyncio                 1.5.6\n",
      "networkx                     2.8.7\n",
      "notebook                     6.5.1\n",
      "notebook-shim                0.1.0\n",
      "numpy                        1.22.2\n",
      "oauthlib                     3.2.2\n",
      "opencv-contrib-python        4.5.5.62\n",
      "opencv-python                4.5.5.62\n",
      "opt-einsum                   3.3.0\n",
      "outcome                      1.2.0\n",
      "packaging                    21.3\n",
      "pandas                       1.5.1\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.3\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       9.0.1\n",
      "pip                          22.3\n",
      "pkgutil_resolve_name         1.3.10\n",
      "prometheus-client            0.15.0\n",
      "prompt-toolkit               3.0.31\n",
      "protobuf                     3.19.6\n",
      "psutil                       5.9.2\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.4.8\n",
      "pyasn1-modules               0.2.8\n",
      "pycparser                    2.21\n",
      "Pygments                     2.13.0\n",
      "pyparsing                    3.0.7\n",
      "pyrsistent                   0.18.1\n",
      "PySocks                      1.7.1\n",
      "python-dateutil              2.8.2\n",
      "python-dotenv                0.21.0\n",
      "pytz                         2022.4\n",
      "pyvis                        0.3.0\n",
      "pywin32                      304\n",
      "pywinpty                     2.0.8\n",
      "pyzmq                        24.0.1\n",
      "requests                     2.28.1\n",
      "requests-oauthlib            1.3.1\n",
      "rsa                          4.9\n",
      "scikit-learn                 1.1.3\n",
      "scipy                        1.9.3\n",
      "selenium                     4.5.0\n",
      "Send2Trash                   1.8.0\n",
      "setuptools                   41.2.0\n",
      "six                          1.16.0\n",
      "sklearn                      0.0.post1\n",
      "sniffio                      1.3.0\n",
      "sortedcontainers             2.4.0\n",
      "soupsieve                    2.3.2.post1\n",
      "sqlparse                     0.4.3\n",
      "stack-data                   0.5.1\n",
      "tensorboard                  2.10.1\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow-estimator         2.10.0\n",
      "tensorflow-gpu               2.10.1\n",
      "tensorflow-io-gcs-filesystem 0.28.0\n",
      "termcolor                    2.1.1\n",
      "terminado                    0.16.0\n",
      "threadpoolctl                3.1.0\n",
      "tinycss2                     1.1.1\n",
      "tomli                        2.0.1\n",
      "tornado                      6.2\n",
      "tqdm                         4.64.1\n",
      "traitlets                    5.4.0\n",
      "trio                         0.22.0\n",
      "trio-websocket               0.9.2\n",
      "typing_extensions            4.1.1\n",
      "tzdata                       2022.5\n",
      "urllib3                      1.26.12\n",
      "wcwidth                      0.2.5\n",
      "webdriver-manager            3.8.3\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.4.1\n",
      "Werkzeug                     2.2.2\n",
      "wget                         3.2\n",
      "wheel                        0.38.4\n",
      "wrapt                        1.14.1\n",
      "wsproto                      1.2.0\n",
      "zipp                         3.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cpu config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU') # thias prevent the tensor flow from taking all of the memory\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = tf.config.experimental.list_physical_devices('CPU') # thias prevent the tensor flow from taking all of the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we train one model we'll have to classify  52 cards + 1 joker  cards.\n",
    "this results in 53 classes.\n",
    "therefore we'll train two models - one for finding the number on the card and one for finding the shape on the card."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number:  six ;  face:  clubs\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Training_set.csv')\n",
    "df.head()\n",
    "df_face_split = df.loc[:, 'label'][0].split()\n",
    "print('number: ', df_face_split[0], ';  face: ', df_face_split[2])\n",
    "number_on_Card_list = [i.split()[0] for i in df.loc[:, 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4776"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_on_Card_list = [len(i.split()) for i in df.loc[:, 'label']]\n",
    "counts = pd.DataFrame({'counts': face_on_Card_list})\n",
    "counts['counts'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4776 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      counts\n",
       "0          3\n",
       "1          3\n",
       "2          3\n",
       "3          3\n",
       "4          3\n",
       "...      ...\n",
       "4771       3\n",
       "4772       3\n",
       "4773       3\n",
       "4774       3\n",
       "4775       3\n",
       "\n",
       "[4776 rows x 1 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts # this is how i found there are joker cards thAT PRODUCE SPLIT LIST WITH LENGTH 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can note that when the card is joker then the len of the card_split is 1 so we need to define a function to specifically handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>joker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "34    joker\n",
       "200   joker\n",
       "229   joker\n",
       "259   joker\n",
       "353   joker\n",
       "...     ...\n",
       "4574  joker\n",
       "4592  joker\n",
       "4598  joker\n",
       "4646  joker\n",
       "4707  joker\n",
       "\n",
       "[81 rows x 1 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['label']][df['label']=='joker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'joker',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'joker',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'joker',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'joker',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'joker',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'joker',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'joker',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'joker',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'joker',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'joker',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'joker',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'joker',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'joker',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'spades',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'diamonds',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'spades',\n",
       " 'clubs',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " 'diamonds',\n",
       " 'clubs',\n",
       " 'hearts',\n",
       " 'hearts',\n",
       " 'spades',\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_card_face(card):\n",
    "    card_split = card.split()\n",
    "    if(len(card_split) == 1):\n",
    "         return card_split[0]\n",
    "    else:\n",
    "        return card_split[2]\n",
    "\n",
    "\n",
    "face_on_Card_list = [find_card_face(card) for card in df.loc[:, 'label']]\n",
    "face_on_Card_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['six',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'king',\n",
       " 'ten',\n",
       " 'jack',\n",
       " 'three',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'seven',\n",
       " 'six',\n",
       " 'jack',\n",
       " 'ten',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'four',\n",
       " 'ten',\n",
       " 'joker',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'five',\n",
       " 'three',\n",
       " 'four',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'seven',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'six',\n",
       " 'king',\n",
       " 'six',\n",
       " 'two',\n",
       " 'nine',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'nine',\n",
       " 'king',\n",
       " 'queen',\n",
       " 'ace',\n",
       " 'eight',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'ace',\n",
       " 'five',\n",
       " 'six',\n",
       " 'two',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'seven',\n",
       " 'two',\n",
       " 'ace',\n",
       " 'five',\n",
       " 'ace',\n",
       " 'two',\n",
       " 'four',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'three',\n",
       " 'five',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'two',\n",
       " 'jack',\n",
       " 'two',\n",
       " 'three',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'five',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'jack',\n",
       " 'king',\n",
       " 'five',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'five',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'two',\n",
       " 'nine',\n",
       " 'four',\n",
       " 'jack',\n",
       " 'three',\n",
       " 'three',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'ten',\n",
       " 'five',\n",
       " 'ace',\n",
       " 'four',\n",
       " 'seven',\n",
       " 'four',\n",
       " 'two',\n",
       " 'three',\n",
       " 'king',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'king',\n",
       " 'king',\n",
       " 'six',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'eight',\n",
       " 'three',\n",
       " 'king',\n",
       " 'five',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'two',\n",
       " 'jack',\n",
       " 'king',\n",
       " 'six',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'two',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'five',\n",
       " 'eight',\n",
       " 'ten',\n",
       " 'ten',\n",
       " 'ten',\n",
       " 'ace',\n",
       " 'five',\n",
       " 'two',\n",
       " 'four',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'jack',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'four',\n",
       " 'five',\n",
       " 'seven',\n",
       " 'three',\n",
       " 'nine',\n",
       " 'two',\n",
       " 'jack',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'five',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'jack',\n",
       " 'king',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'four',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'two',\n",
       " 'ten',\n",
       " 'five',\n",
       " 'six',\n",
       " 'two',\n",
       " 'king',\n",
       " 'king',\n",
       " 'eight',\n",
       " 'ten',\n",
       " 'four',\n",
       " 'joker',\n",
       " 'two',\n",
       " 'two',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'jack',\n",
       " 'six',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'four',\n",
       " 'three',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'ten',\n",
       " 'ten',\n",
       " 'six',\n",
       " 'two',\n",
       " 'four',\n",
       " 'seven',\n",
       " 'two',\n",
       " 'eight',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'two',\n",
       " 'king',\n",
       " 'ten',\n",
       " 'joker',\n",
       " 'seven',\n",
       " 'two',\n",
       " 'six',\n",
       " 'king',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'six',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'ten',\n",
       " 'eight',\n",
       " 'queen',\n",
       " 'nine',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'queen',\n",
       " 'two',\n",
       " 'joker',\n",
       " 'king',\n",
       " 'ten',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'three',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'ten',\n",
       " 'jack',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'three',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'three',\n",
       " 'queen',\n",
       " 'king',\n",
       " 'ace',\n",
       " 'three',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'two',\n",
       " 'ten',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'six',\n",
       " 'four',\n",
       " 'three',\n",
       " 'king',\n",
       " 'four',\n",
       " 'six',\n",
       " 'king',\n",
       " 'four',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'three',\n",
       " 'nine',\n",
       " 'ace',\n",
       " 'five',\n",
       " 'two',\n",
       " 'nine',\n",
       " 'three',\n",
       " 'king',\n",
       " 'king',\n",
       " 'four',\n",
       " 'eight',\n",
       " 'queen',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'ace',\n",
       " 'eight',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'three',\n",
       " 'jack',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'queen',\n",
       " 'ten',\n",
       " 'ten',\n",
       " 'ten',\n",
       " 'two',\n",
       " 'king',\n",
       " 'ace',\n",
       " 'four',\n",
       " 'jack',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'four',\n",
       " 'ten',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'king',\n",
       " 'two',\n",
       " 'jack',\n",
       " 'joker',\n",
       " 'queen',\n",
       " 'four',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'king',\n",
       " 'jack',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'four',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'five',\n",
       " 'ace',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'five',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'king',\n",
       " 'five',\n",
       " 'six',\n",
       " 'king',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'ace',\n",
       " 'nine',\n",
       " 'ace',\n",
       " 'four',\n",
       " 'ten',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'four',\n",
       " 'five',\n",
       " 'three',\n",
       " 'two',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'jack',\n",
       " 'five',\n",
       " 'ace',\n",
       " 'jack',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'three',\n",
       " 'three',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'jack',\n",
       " 'queen',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'queen',\n",
       " 'two',\n",
       " 'two',\n",
       " 'ace',\n",
       " 'ace',\n",
       " 'nine',\n",
       " 'three',\n",
       " 'nine',\n",
       " 'nine',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'four',\n",
       " 'two',\n",
       " 'six',\n",
       " 'three',\n",
       " 'ten',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'four',\n",
       " 'king',\n",
       " 'three',\n",
       " 'nine',\n",
       " 'king',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'ten',\n",
       " 'two',\n",
       " 'nine',\n",
       " 'five',\n",
       " 'queen',\n",
       " 'two',\n",
       " 'six',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'five',\n",
       " 'queen',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'four',\n",
       " 'seven',\n",
       " 'five',\n",
       " 'eight',\n",
       " 'seven',\n",
       " 'ace',\n",
       " 'ten',\n",
       " 'three',\n",
       " 'six',\n",
       " 'six',\n",
       " 'three',\n",
       " 'king',\n",
       " 'eight',\n",
       " 'ace',\n",
       " 'jack',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'jack',\n",
       " 'five',\n",
       " 'six',\n",
       " 'four',\n",
       " 'queen',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'ten',\n",
       " 'five',\n",
       " 'ace',\n",
       " 'eight',\n",
       " 'ten',\n",
       " 'four',\n",
       " 'ten',\n",
       " 'ace',\n",
       " 'seven',\n",
       " 'seven',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'king',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'joker',\n",
       " 'ace',\n",
       " 'seven',\n",
       " 'three',\n",
       " 'jack',\n",
       " 'three',\n",
       " 'eight',\n",
       " 'seven',\n",
       " 'jack',\n",
       " 'king',\n",
       " 'two',\n",
       " 'jack',\n",
       " 'queen',\n",
       " 'joker',\n",
       " 'nine',\n",
       " 'jack',\n",
       " 'two',\n",
       " 'two',\n",
       " 'eight',\n",
       " 'eight',\n",
       " 'king',\n",
       " 'three',\n",
       " 'jack',\n",
       " 'ace',\n",
       " 'two',\n",
       " 'king',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'ten',\n",
       " 'ten',\n",
       " 'five',\n",
       " 'two',\n",
       " 'king',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'five',\n",
       " 'nine',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'two',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'four',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'jack',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'king',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'jack',\n",
       " 'ace',\n",
       " 'nine',\n",
       " 'five',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'ace',\n",
       " 'jack',\n",
       " 'king',\n",
       " 'king',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'five',\n",
       " 'king',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'five',\n",
       " 'king',\n",
       " 'four',\n",
       " 'ten',\n",
       " 'ace',\n",
       " 'ace',\n",
       " 'ace',\n",
       " 'jack',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'three',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'two',\n",
       " 'eight',\n",
       " 'ten',\n",
       " 'jack',\n",
       " 'king',\n",
       " 'queen',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'five',\n",
       " 'ace',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'two',\n",
       " 'two',\n",
       " 'jack',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'king',\n",
       " 'five',\n",
       " 'eight',\n",
       " 'joker',\n",
       " 'two',\n",
       " 'two',\n",
       " 'ace',\n",
       " 'eight',\n",
       " 'ace',\n",
       " 'nine',\n",
       " 'joker',\n",
       " 'ten',\n",
       " 'five',\n",
       " 'king',\n",
       " 'joker',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'five',\n",
       " 'six',\n",
       " 'ace',\n",
       " 'joker',\n",
       " 'ten',\n",
       " 'two',\n",
       " 'two',\n",
       " 'six',\n",
       " 'five',\n",
       " 'four',\n",
       " 'ten',\n",
       " 'ace',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'king',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'queen',\n",
       " 'king',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'three',\n",
       " 'four',\n",
       " 'two',\n",
       " 'nine',\n",
       " 'king',\n",
       " 'king',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'jack',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'nine',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'six',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'two',\n",
       " 'king',\n",
       " 'six',\n",
       " 'five',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'king',\n",
       " 'four',\n",
       " 'six',\n",
       " 'six',\n",
       " 'two',\n",
       " 'four',\n",
       " 'jack',\n",
       " 'eight',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'king',\n",
       " 'four',\n",
       " 'five',\n",
       " 'six',\n",
       " 'jack',\n",
       " 'ten',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'seven',\n",
       " 'three',\n",
       " 'four',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'three',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'five',\n",
       " 'two',\n",
       " 'two',\n",
       " 'six',\n",
       " 'two',\n",
       " 'queen',\n",
       " 'three',\n",
       " 'nine',\n",
       " 'three',\n",
       " 'two',\n",
       " 'eight',\n",
       " 'jack',\n",
       " 'three',\n",
       " 'queen',\n",
       " 'nine',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'four',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'four',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'king',\n",
       " 'four',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'queen',\n",
       " 'eight',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'ten',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'seven',\n",
       " 'jack',\n",
       " 'joker',\n",
       " 'queen',\n",
       " 'two',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'three',\n",
       " 'jack',\n",
       " 'five',\n",
       " 'five',\n",
       " 'seven',\n",
       " 'king',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'four',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'ten',\n",
       " 'three',\n",
       " 'queen',\n",
       " 'five',\n",
       " 'king',\n",
       " 'five',\n",
       " 'king',\n",
       " 'eight',\n",
       " 'six',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'nine',\n",
       " 'jack',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'ace',\n",
       " 'three',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'queen',\n",
       " 'nine',\n",
       " 'jack',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'ace',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'jack',\n",
       " 'ten',\n",
       " 'two',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'six',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'six',\n",
       " 'ace',\n",
       " 'ten',\n",
       " 'seven',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'four',\n",
       " 'four',\n",
       " 'ten',\n",
       " 'king',\n",
       " 'jack',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'four',\n",
       " 'four',\n",
       " 'king',\n",
       " 'four',\n",
       " 'eight',\n",
       " 'two',\n",
       " 'two',\n",
       " 'joker',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'two',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'four',\n",
       " 'three',\n",
       " 'queen',\n",
       " 'two',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'jack',\n",
       " 'queen',\n",
       " 'king',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'three',\n",
       " 'six',\n",
       " 'six',\n",
       " 'four',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'four',\n",
       " 'three',\n",
       " 'ten',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'three',\n",
       " 'five',\n",
       " 'nine',\n",
       " 'six',\n",
       " 'king',\n",
       " 'queen',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'king',\n",
       " 'ten',\n",
       " 'two',\n",
       " 'ace',\n",
       " 'six',\n",
       " 'ace',\n",
       " 'king',\n",
       " 'jack',\n",
       " 'four',\n",
       " 'jack',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'ace',\n",
       " 'king',\n",
       " 'jack',\n",
       " 'ten',\n",
       " 'seven',\n",
       " 'five',\n",
       " 'jack',\n",
       " 'jack',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'king',\n",
       " 'ten',\n",
       " 'ace',\n",
       " 'king',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'king',\n",
       " 'seven',\n",
       " 'six',\n",
       " 'three',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'two',\n",
       " 'six',\n",
       " 'four',\n",
       " 'three',\n",
       " 'seven',\n",
       " 'queen',\n",
       " 'five',\n",
       " 'king',\n",
       " 'four',\n",
       " 'seven',\n",
       " 'nine',\n",
       " 'king',\n",
       " 'king',\n",
       " 'ace',\n",
       " 'five',\n",
       " 'nine',\n",
       " 'four',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'ace',\n",
       " 'two',\n",
       " 'queen',\n",
       " 'two',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'ace',\n",
       " 'ace',\n",
       " 'two',\n",
       " 'queen',\n",
       " 'ten',\n",
       " 'six',\n",
       " 'six',\n",
       " 'king',\n",
       " 'eight',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'five',\n",
       " 'two',\n",
       " 'seven',\n",
       " 'four',\n",
       " 'ten',\n",
       " 'three',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'four',\n",
       " 'six',\n",
       " 'eight',\n",
       " 'king',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'three',\n",
       " 'ten',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'two',\n",
       " 'six',\n",
       " 'nine',\n",
       " 'five',\n",
       " 'five',\n",
       " 'ace',\n",
       " 'ace',\n",
       " 'queen',\n",
       " 'ten',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'queen',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'five',\n",
       " 'queen',\n",
       " 'five',\n",
       " 'five',\n",
       " 'jack',\n",
       " 'six',\n",
       " 'queen',\n",
       " 'seven',\n",
       " 'king',\n",
       " ...]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_on_Card_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>number_on_card</th>\n",
       "      <th>face_on_card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>six of clubs</td>\n",
       "      <td>six</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>queen of hearts</td>\n",
       "      <td>queen</td>\n",
       "      <td>hearts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>seven of diamonds</td>\n",
       "      <td>seven</td>\n",
       "      <td>diamonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>six of spades</td>\n",
       "      <td>six</td>\n",
       "      <td>spades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>eight of spades</td>\n",
       "      <td>eight</td>\n",
       "      <td>spades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>Image_4772.jpg</td>\n",
       "      <td>ace of clubs</td>\n",
       "      <td>ace</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>Image_4773.jpg</td>\n",
       "      <td>jack of hearts</td>\n",
       "      <td>jack</td>\n",
       "      <td>hearts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>Image_4774.jpg</td>\n",
       "      <td>five of clubs</td>\n",
       "      <td>five</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>Image_4775.jpg</td>\n",
       "      <td>two of clubs</td>\n",
       "      <td>two</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>Image_4776.jpg</td>\n",
       "      <td>five of clubs</td>\n",
       "      <td>five</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4776 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename              label number_on_card face_on_card\n",
       "0        Image_1.jpg       six of clubs            six        clubs\n",
       "1        Image_2.jpg    queen of hearts          queen       hearts\n",
       "2        Image_3.jpg  seven of diamonds          seven     diamonds\n",
       "3        Image_4.jpg      six of spades            six       spades\n",
       "4        Image_5.jpg    eight of spades          eight       spades\n",
       "...              ...                ...            ...          ...\n",
       "4771  Image_4772.jpg       ace of clubs            ace        clubs\n",
       "4772  Image_4773.jpg     jack of hearts           jack       hearts\n",
       "4773  Image_4774.jpg      five of clubs           five        clubs\n",
       "4774  Image_4775.jpg       two of clubs            two        clubs\n",
       "4775  Image_4776.jpg      five of clubs           five        clubs\n",
       "\n",
       "[4776 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df\n",
    "df_copy['number_on_card'] = number_on_Card_list\n",
    "df_copy['face_on_card'] = face_on_Card_list\n",
    "df\n",
    "# now  we have two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spades      1255\n",
       "clubs       1168\n",
       "diamonds    1142\n",
       "hearts      1130\n",
       "joker         81\n",
       "Name: face_on_card, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['face_on_card'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pandas.core.series.Series.to_dict(self, into: 'type[dict]' = <class 'dict'>) -> 'dict'>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_list = df['number_on_card'].value_counts()\n",
    "type(count_list).to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data provides us with the  label (target variable -> card face) and name of the file contianing the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import imghdr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./data')\n",
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b0485bfc40>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list_of_imgs = os.listdir('./data/train')\n",
    "img = cv.imread('./data/train/Image_1.jpg')\n",
    "print(img.shape)\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the data that we're working with are RGB(three channels) 255x244 pixel images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*IGNORE THE FOLLOWING CODE BLOCK*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_class in os.listdir(data_dir):\n",
    "#     for image in os.listir(os.path.join(data_dir, image_class)):\n",
    "#         image_path = os.path.join(data_dir, image_class, image)\n",
    "#         try:\n",
    "#             img = cv.imread(image_path)\n",
    "#             p\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this provides you with somwdata pipline that helps you to work with large ammounts of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollections_abc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrackable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompositeTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;34m\"\"\"Represents a potentially large set of elements.\n",
      "\n",
      "  The `tf.data.Dataset` API supports writing descriptive and efficient input\n",
      "  pipelines. `Dataset` usage follows a common pattern:\n",
      "\n",
      "  1. Create a source dataset from your input data.\n",
      "  2. Apply dataset transformations to preprocess the data.\n",
      "  3. Iterate over the dataset and process the elements.\n",
      "\n",
      "  Iteration happens in a streaming fashion, so the full dataset does not need to\n",
      "  fit into memory.\n",
      "\n",
      "  Source Datasets:\n",
      "\n",
      "  The simplest way to create a dataset is to create it from a python `list`:\n",
      "\n",
      "  >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "  >>> for element in dataset:\n",
      "  ...   print(element)\n",
      "  tf.Tensor(1, shape=(), dtype=int32)\n",
      "  tf.Tensor(2, shape=(), dtype=int32)\n",
      "  tf.Tensor(3, shape=(), dtype=int32)\n",
      "\n",
      "  To process lines from files, use `tf.data.TextLineDataset`:\n",
      "\n",
      "  >>> dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])\n",
      "\n",
      "  To process records written in the `TFRecord` format, use `TFRecordDataset`:\n",
      "\n",
      "  >>> dataset = tf.data.TFRecordDataset([\"file1.tfrecords\", \"file2.tfrecords\"])\n",
      "\n",
      "  To create a dataset of all files matching a pattern, use\n",
      "  `tf.data.Dataset.list_files`:\n",
      "\n",
      "  ```python\n",
      "  dataset = tf.data.Dataset.list_files(\"/path/*.txt\")\n",
      "  ```\n",
      "\n",
      "  See `tf.data.FixedLengthRecordDataset` and `tf.data.Dataset.from_generator`\n",
      "  for more ways to create datasets.\n",
      "\n",
      "  Transformations:\n",
      "\n",
      "  Once you have a dataset, you can apply transformations to prepare the data for\n",
      "  your model:\n",
      "\n",
      "  >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "  >>> dataset = dataset.map(lambda x: x*2)\n",
      "  >>> list(dataset.as_numpy_iterator())\n",
      "  [2, 4, 6]\n",
      "\n",
      "  Common Terms:\n",
      "\n",
      "  **Element**: A single output from calling `next()` on a dataset iterator.\n",
      "    Elements may be nested structures containing multiple components. For\n",
      "    example, the element `(1, (3, \"apple\"))` has one tuple nested in another\n",
      "    tuple. The components are `1`, `3`, and `\"apple\"`.\n",
      "\n",
      "  **Component**: The leaf in the nested structure of an element.\n",
      "\n",
      "  Supported types:\n",
      "\n",
      "  Elements can be nested structures of tuples, named tuples, and dictionaries.\n",
      "  Note that Python lists are *not* treated as nested structures of components.\n",
      "  Instead, lists are converted to tensors and treated as components. For\n",
      "  example, the element `(1, [1, 2, 3])` has only two components; the tensor `1`\n",
      "  and the tensor `[1, 2, 3]`. Element components can be of any type\n",
      "  representable by `tf.TypeSpec`, including `tf.Tensor`, `tf.data.Dataset`,\n",
      "  `tf.sparse.SparseTensor`, `tf.RaggedTensor`, and `tf.TensorArray`.\n",
      "\n",
      "  ```python\n",
      "  a = 1 # Integer element\n",
      "  b = 2.0 # Float element\n",
      "  c = (1, 2) # Tuple element with 2 components\n",
      "  d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components\n",
      "  Point = collections.namedtuple(\"Point\", [\"x\", \"y\"])\n",
      "  e = Point(1, 2) # Named tuple\n",
      "  f = tf.data.Dataset.range(10) # Dataset element\n",
      "  ```\n",
      "\n",
      "  For more information,\n",
      "  read [this guide](https://www.tensorflow.org/guide/data).\n",
      "  \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a DatasetV2 object.\n",
      "\n",
      "    This is a difference between DatasetV1 and DatasetV2. DatasetV1 does not\n",
      "    take anything in its constructor whereas in the DatasetV2, we expect\n",
      "    subclasses to create a variant_tensor and pass it in to the super() call.\n",
      "\n",
      "    Args:\n",
      "      variant_tensor: A DT_VARIANT tensor that represents the dataset.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Initialize the options for this dataset and its inputs.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0minput_dataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0minput_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetV1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# If the V1 dataset does not have the `_dataset` attribute, we assume it\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# is a dataset source and hence does not have options. Otherwise, we\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# grab the options of `_dataset` object\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_dataset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34mf\"Each input of dataset {type(self)} should be a subclass of \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34mf\"`tf.data.Dataset` but encountered \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34mf\"{type(input_dataset._dataset)}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0minput_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0minput_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34mf\"Each input of dataset {type(self)} should be a subclass of \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34mf\"`tf.data.Dataset` but encountered {type(input_dataset)}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0minput_options\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mutable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_variant_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor_attr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_variant_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The `_variant_tensor` property cannot be modified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecated_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Use external_state_policy instead\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                               \u001b[1;34m\"allow_stateful\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_as_serialized_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mallow_stateful\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mstrip_device_assignment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mexternal_state_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExternalStatePolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWARN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Produces serialized graph representation of the dataset.\n",
      "\n",
      "    Args:\n",
      "      allow_stateful: If true, we allow stateful ops to be present in the graph\n",
      "        def. In that case, the state in these ops would be thrown away.\n",
      "      strip_device_assignment: If true, non-local (i.e. job and task) device\n",
      "        assignment is stripped from ops in the serialized graph.\n",
      "      external_state_policy: The ExternalStatePolicy enum that determines how we\n",
      "        handle input pipelines that depend on external state. By default, its\n",
      "        set to WARN.\n",
      "\n",
      "    Returns:\n",
      "      A scalar `tf.Tensor` of `tf.string` type, representing this dataset as a\n",
      "      serialized graph.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mexternal_state_policy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexternal_state_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_to_graph_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mexternal_state_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mstrip_device_assignment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_device_assignment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mstrip_device_assignment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mallow_stateful\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_stateful\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mstrip_device_assignment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_device_assignment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_stateful\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_stateful\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_track_assets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Finds and tracks nodes in `graph_def` that refer to asset files.\n",
      "\n",
      "    Args:\n",
      "      graph_def: Serialized graph representation of this dataset.\n",
      "\n",
      "    Returns:\n",
      "      A dictionary mapping the node name of an asset constant to a tracked\n",
      "      `asset.Asset` object.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0masset_tracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FileIdentity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0masset_tracker\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mtensor_proto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CPU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mnode_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsing_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0mtensor_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0masset_tracker\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_track_trackable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAsset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_trackable_children\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                          \u001b[0msave_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtracking_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHECKPOINT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                          \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0msave_type\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtracking_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# _trace_variant_creation only works when executing eagerly, so we don't\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# want to run it in the object initialization.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mdef_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mresource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trace_variant_creation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mresource\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Trigger asset tracking\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mchildren\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_children\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mchildren\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"_variant_tracker\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VariantTracker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                   \u001b[0m_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mchildren\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_trace_variant_creation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Traces a function which outputs a variant `tf.Tensor` for this dataset.\n",
      "\n",
      "    Note that creating this function involves evaluating an op, and is currently\n",
      "    only supported when executing eagerly.\n",
      "\n",
      "    Returns:\n",
      "      A zero-argument `ConcreteFunction` which outputs a variant `tf.Tensor`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvariant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34m\"Constructing a tf.function that reproduces a given dataset is only \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34m\"supported for datasets created eagerly. Please file a feature \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34m\"request if this is important to you.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CPU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mgraph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_serialized_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexternal_state_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions_lib\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                    \u001b[1;33m.\u001b[0m\u001b[0mExternalStatePolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAIL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moutput_node_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"_Retval\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moutput_node_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_node_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34mf\"Dataset graph is expected to only have one return value but found \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34mf\"{len(output_node_names)} return values: {output_node_names}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moutput_node_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfile_path_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# When building a tf.function, track files as `saved_model.Asset`s.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0masset_tracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_track_assets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0massets_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0masset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfile_path_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massets_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Add functions used in this Dataset to the function's graph, since they\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# need to follow it around (and for example be added to a SavedModel which\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# references the dataset).\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvariant_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_from_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_node_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":0\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcaptures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_path_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mused_function\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mused_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariant_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mvariant_function\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns a list of the input datasets of the dataset.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{type(self)}._inputs()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_attr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The `_graph` property cannot be modified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;31m# TODO(jsimsa): Change this to be the transitive closure of functions used\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;31m# by this dataset and its inputs.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns a list of functions associated with this dataset.\n",
      "\n",
      "    Returns:\n",
      "      A list of `StructuredFunctionWrapper` objects.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns the options tensor for this dataset.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_options_tensor_to_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserialized_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Converts options tensor to tf.data.Options object.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized_options\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mpb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_options_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mserialized_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns the options for this dataset and its inputs.\n",
      "\n",
      "    Returns:\n",
      "      A `tf.data.Options` object representing the dataset options.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options_tensor_to_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mutable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"To make it possible to preserve tf.data options across \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34m\"serialization boundaries, their implementation has moved to \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34m\"be part of the TensorFlow graph. As a consequence, the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34m\"options value is in general no longer known at graph \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34m\"construction time. Invoking this method in graph mode \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34m\"retains the legacy behavior of the original implementation, \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34m\"but note that the returned value might not reflect the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34m\"actual value of the options.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_apply_debug_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# Disable autotuning and static optimizations that could introduce\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# parallelism or asynchrony.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautotune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_optimization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_parallelization\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_optimization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_and_batch_fusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_optimization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_parallelization\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_OptionsDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates an iterator for elements of this dataset.\n",
      "\n",
      "    The returned iterator implements the Python Iterator protocol.\n",
      "\n",
      "    Returns:\n",
      "      An `tf.data.Iterator` for the elements of this dataset.\n",
      "\n",
      "    Raises:\n",
      "      RuntimeError: If not inside of tf.function and not executing eagerly.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`tf.data.Dataset` only supports Python-style \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                         \u001b[1;34m\"iteration in eager mode or within tf.function.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# Required as __len__ is defined\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[0m__nonzero__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__bool__\u001b[0m  \u001b[1;31m# Python 2 backward compatibility\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns the length of the dataset if it is known and finite.\n",
      "\n",
      "    This method requires that you are running in eager mode, and that the\n",
      "    length of the dataset is known and non-infinite. When the length may be\n",
      "    unknown or infinite, or if you are running in graph mode, use\n",
      "    `tf.data.Dataset.cardinality` instead.\n",
      "\n",
      "    Returns:\n",
      "      An integer representing the length of the dataset.\n",
      "\n",
      "    Raises:\n",
      "      RuntimeError: If the dataset length is unknown or infinite, or if eager\n",
      "        execution is not enabled.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`tf.data.Dataset` only supports `len` in eager mode. \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34m\"Use `tf.data.Dataset.cardinality()` instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mINFINITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The dataset is infinite.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mUNKNOWN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The dataset length is unknown.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0melement_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"The type specification of an element of this dataset.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> dataset.element_spec\n",
      "    TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "\n",
      "    For more information,\n",
      "    read [this guide](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      "\n",
      "    Returns:\n",
      "      A (nested) structure of `tf.TypeSpec` objects matching the structure of an\n",
      "      element of this dataset and specifying the type of individual components.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{type(self)}.element_spec()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtype_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[1;34mf\"<{type_.__name__} element_spec={self.element_spec}>\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m__debug_string__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns a string showing the type of the dataset and its inputs.\n",
      "\n",
      "    This string is intended only for debugging purposes, and may change without\n",
      "    warning.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mto_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Stack of (dataset, depth) pairs.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mwhile\u001b[0m \u001b[0mto_process\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mto_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns an iterator which converts all elements of the dataset to numpy.\n",
      "\n",
      "    Use `as_numpy_iterator` to inspect the content of your dataset. To see\n",
      "    element shapes and types, print dataset elements directly instead of using\n",
      "    `as_numpy_iterator`.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> for element in dataset:\n",
      "    ...   print(element)\n",
      "    tf.Tensor(1, shape=(), dtype=int32)\n",
      "    tf.Tensor(2, shape=(), dtype=int32)\n",
      "    tf.Tensor(3, shape=(), dtype=int32)\n",
      "\n",
      "    This method requires that you are running in eager mode and the dataset's\n",
      "    element_spec contains only `TensorSpec` components.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> for element in dataset.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> print(list(dataset.as_numpy_iterator()))\n",
      "    [1, 2, 3]\n",
      "\n",
      "    `as_numpy_iterator()` will preserve the nested structure of dataset\n",
      "    elements.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\n",
      "    ...                                               'b': [5, 6]})\n",
      "    >>> list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\n",
      "    ...                                       {'a': (2, 4), 'b': 6}]\n",
      "    True\n",
      "\n",
      "    Returns:\n",
      "      An iterable over the elements of the dataset, with their tensors converted\n",
      "      to numpy arrays.\n",
      "\n",
      "    Raises:\n",
      "      TypeError: if an element contains a non-`Tensor` value.\n",
      "      RuntimeError: if eager execution is not enabled.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`tf.data.Dataset.as_numpy_iterator()` is only \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                         \u001b[1;34m\"supported in eager mode.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mcomponent_spec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33m(\u001b[0m\u001b[0mtensor_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRaggedTensorSpec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                         \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoneTensorSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34mf\"`tf.data.Dataset.as_numpy_iterator()` is not supported for \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34mf\"datasets that produce values of type {component_spec.value_type}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_NumpyIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_flat_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns a list `tf.TensorShapes`s for the element tensor representation.\n",
      "\n",
      "    Returns:\n",
      "      A list `tf.TensorShapes`s for the element tensor representation.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_flat_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns a list `tf.DType`s for the element tensor representation.\n",
      "\n",
      "    Returns:\n",
      "      A list `tf.DType`s for the element tensor representation.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_flat_tensor_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_flat_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Helper for setting `output_shapes` and `output_types` attrs of an op.\n",
      "\n",
      "    Most dataset op constructors expect `output_shapes` and `output_types`\n",
      "    arguments that represent the flattened structure of an element. This helper\n",
      "    function generates these attrs as a keyword argument dictionary, allowing\n",
      "    `Dataset._variant_tensor` implementations to pass `**self._flat_structure`\n",
      "    to the op constructor.\n",
      "\n",
      "    Returns:\n",
      "      A dictionary of keyword arguments that can be passed to a dataset op\n",
      "      constructor.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"output_shapes\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Helper for generating dataset metadata.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_and_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_common_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Helper for generating arguments that are common across most dataset ops.\n",
      "\n",
      "    Most dataset op constructors expect `output_shapes` and `output_types`\n",
      "    arguments that represent the flattened structure of an element, as well as a\n",
      "    `metadata` argument for additional metadata such as user-defined dataset\n",
      "    name. This helper function generates common attributes as a keyword argument\n",
      "    dictionary, allowing `Dataset._variant_tensor` implementations to pass\n",
      "    `**self._common_args` to the op constructor.\n",
      "\n",
      "    Returns:\n",
      "      A dictionary of keyword arguments that can be passed to a dataset op\n",
      "      constructor.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"metadata\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"output_shapes\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0m_type_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` with a single element, comprising the given tensors.\n",
      "\n",
      "    `from_tensors` produces a dataset containing only a single element. To slice\n",
      "    the input tensor into multiple elements, use `from_tensor_slices` instead.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([1, 2, 3], dtype=int32)]\n",
      "    >>> dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A'))\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [(array([1, 2, 3], dtype=int32), b'A')]\n",
      "\n",
      "    >>> # You can use `from_tensors` to produce a dataset which repeats\n",
      "    >>> # the same example many times.\n",
      "    >>> example = tf.constant([1,2,3])\n",
      "    >>> dataset = tf.data.Dataset.from_tensors(example).repeat(2)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([1, 2, 3], dtype=int32), array([1, 2, 3], dtype=int32)]\n",
      "\n",
      "    Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      "    enabled, the values will be embedded in the graph as one or more\n",
      "    `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      "    memory and run into byte limits of graph serialization. If `tensors`\n",
      "    contains one or more large NumPy arrays, consider the alternative described\n",
      "    in [this\n",
      "    guide](https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      "\n",
      "    Args:\n",
      "      tensors: A dataset \"element\". Supported values are documented\n",
      "        [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "\n",
      "    The given tensors are sliced along their first dimension. This operation\n",
      "    preserves the structure of the input tensors, removing the first dimension\n",
      "    of each tensor and using it as the dataset dimension. All input tensors\n",
      "    must have the same size in their first dimensions.\n",
      "\n",
      "    >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 2, 3]\n",
      "\n",
      "    >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
      "\n",
      "    >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
      "    >>> # scalar tensors.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [(1, 3, 5), (2, 4, 6)]\n",
      "\n",
      "    >>> # Dictionary structure is also preserved.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
      "    >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
      "    ...                                       {'a': 2, 'b': 4}]\n",
      "    True\n",
      "\n",
      "    >>> # Two tensors can be combined into one Dataset object.\n",
      "    >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
      "    >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
      "    >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
      "    >>> # Both the features and the labels tensors can be converted\n",
      "    >>> # to a Dataset object separately and combined after.\n",
      "    >>> features_dataset = Dataset.from_tensor_slices(features)\n",
      "    >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
      "    >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
      "    >>> # A batched feature and label set can be converted to a Dataset\n",
      "    >>> # in similar fashion.\n",
      "    >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
      "    ...                                 [[2, 1], [1, 2]],\n",
      "    ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
      "    >>> batched_labels = tf.constant([['A', 'A'],\n",
      "    ...                               ['B', 'B'],\n",
      "    ...                               ['A', 'B']], shape=(3, 2, 1))\n",
      "    >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
      "    >>> for element in dataset.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    (array([[1, 3],\n",
      "           [2, 3]], dtype=int32), array([[b'A'],\n",
      "           [b'A']], dtype=object))\n",
      "    (array([[2, 1],\n",
      "           [1, 2]], dtype=int32), array([[b'B'],\n",
      "           [b'B']], dtype=object))\n",
      "    (array([[3, 3],\n",
      "           [3, 2]], dtype=int32), array([[b'A'],\n",
      "           [b'B']], dtype=object))\n",
      "\n",
      "    Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      "    enabled, the values will be embedded in the graph as one or more\n",
      "    `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      "    memory and run into byte limits of graph serialization. If `tensors`\n",
      "    contains one or more large NumPy arrays, consider the alternative described\n",
      "    in [this guide](\n",
      "    https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      "\n",
      "    Args:\n",
      "      tensors: A dataset element, whose components have the same first\n",
      "        dimension. Supported values are documented\n",
      "        [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Stores outstanding iterators created from a Python generator.\n",
      "\n",
      "    This class keeps track of potentially multiple iterators that may have\n",
      "    been created from a generator, e.g. in the case that the dataset is\n",
      "    repeated, or nested within a parallel computation.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m  \u001b[1;31m# GUARDED_BY(self._lock)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_normalize_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# In debug mode, iterator ids may be eagerly-generated np.arrays instead\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# of Tensors. We convert them to scalars to make them hashable.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_next_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_id\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_id\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# NOTE(mrry): Explicitly create an array of `np.int64` because implicit\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# casting in `py_func()` will create an array of `np.int32` on Windows,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# leading to a runtime error.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0miterator_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0miterator_completed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecated_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Use output_signature instead\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                               \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_shapes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mfrom_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                     \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                     \u001b[0moutput_signature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` whose elements are generated by `generator`.\n",
      "\n",
      "    Note: The current implementation of `Dataset.from_generator()` uses\n",
      "    `tf.numpy_function` and inherits the same constraints. In particular, it\n",
      "    requires the dataset and iterator related operations to be placed\n",
      "    on a device in the same process as the Python program that called\n",
      "    `Dataset.from_generator()`. In particular, using `from_generator` will\n",
      "    preclude the use of tf.data service for scaling out dataset processing.\n",
      "    The body of `generator` will not be serialized in a `GraphDef`, and you\n",
      "    should not use this method if you need to serialize your model and restore\n",
      "    it in a different environment.\n",
      "\n",
      "    The `generator` argument must be a callable object that returns\n",
      "    an object that supports the `iter()` protocol (e.g. a generator function).\n",
      "\n",
      "    The elements generated by `generator` must be compatible with either the\n",
      "    given `output_signature` argument or with the given `output_types` and\n",
      "    (optionally) `output_shapes` arguments, whichever was specified.\n",
      "\n",
      "    The recommended way to call `from_generator` is to use the\n",
      "    `output_signature` argument. In this case the output will be assumed to\n",
      "    consist of objects with the classes, shapes and types defined by\n",
      "    `tf.TypeSpec` objects from `output_signature` argument:\n",
      "\n",
      "    >>> def gen():\n",
      "    ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n",
      "    ...   yield 42, ragged_tensor\n",
      "    >>>\n",
      "    >>> dataset = tf.data.Dataset.from_generator(\n",
      "    ...      gen,\n",
      "    ...      output_signature=(\n",
      "    ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n",
      "    ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n",
      "    >>>\n",
      "    >>> list(dataset.take(1))\n",
      "    [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n",
      "    <tf.RaggedTensor [[1, 2], [3]]>)]\n",
      "\n",
      "    There is also a deprecated way to call `from_generator` by either with\n",
      "    `output_types` argument alone or together with `output_shapes` argument.\n",
      "    In this case the output of the function will be assumed to consist of\n",
      "    `tf.Tensor` objects with the types defined by `output_types` and with the\n",
      "    shapes which are either unknown or defined by `output_shapes`.\n",
      "\n",
      "    Note: If `generator` depends on mutable global variables or other external\n",
      "    state, be aware that the runtime may invoke `generator` multiple times\n",
      "    (in order to support repeating the `Dataset`) and at any time\n",
      "    between the call to `Dataset.from_generator()` and the production of the\n",
      "    first element from the generator. Mutating global variables or external\n",
      "    state can cause undefined behavior, and we recommend that you explicitly\n",
      "    cache any external state in `generator` before calling\n",
      "    `Dataset.from_generator()`.\n",
      "\n",
      "    Note: While the `output_signature` parameter makes it possible to yield\n",
      "    `Dataset` elements, the scope of `Dataset.from_generator()` should be\n",
      "    limited to logic that cannot be expressed through tf.data operations. Using\n",
      "    tf.data operations within the generator function is an anti-pattern and may\n",
      "    result in incremental memory growth.\n",
      "\n",
      "    Args:\n",
      "      generator: A callable object that returns an object that supports the\n",
      "        `iter()` protocol. If `args` is not specified, `generator` must take no\n",
      "        arguments; otherwise it must take as many arguments as there are values\n",
      "        in `args`.\n",
      "      output_types: (Optional.) A (nested) structure of `tf.DType` objects\n",
      "        corresponding to each component of an element yielded by `generator`.\n",
      "      output_shapes: (Optional.) A (nested) structure of `tf.TensorShape`\n",
      "        objects corresponding to each component of an element yielded by\n",
      "        `generator`.\n",
      "      args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated\n",
      "        and passed to `generator` as NumPy-array arguments.\n",
      "      output_signature: (Optional.) A (nested) structure of `tf.TypeSpec`\n",
      "        objects corresponding to each component of an element yielded by\n",
      "        `generator`.\n",
      "      name: (Optional.) A name for the tf.data operations used by\n",
      "        `from_generator`.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`generator` must be a Python callable.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0moutput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0moutput_types\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The `output_types` argument can not be used together \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"with the `output_signature` argument.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0moutput_shapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The `output_shapes` argument can not be used together \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"with the `output_signature` argument.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTypeSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"`output_signature` must contain objects that are \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                          \u001b[1;34mf\"subclass of `tf.TypeSpec` but found {type(spec)} \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                          \u001b[1;34mf\"which is not.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0moutput_types\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"To specify the output signature you need to provide \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"either the `output_signature` argument or the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"`output_types` argument.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0moutput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0moutput_shapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moutput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moutput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                 \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                 \u001b[0moutput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moutput_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                  \u001b[0mtensor_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                  \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moutput_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0moutput_signature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moutput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0moutput_signature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_n_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"args\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mgenerator_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_iterator_id_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munused_dummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;34m\"\"\"Creates a unique `iterator_id` for each pass over the dataset.\n",
      "\n",
      "      The returned `iterator_id` disambiguates between multiple concurrently\n",
      "      existing iterators.\n",
      "\n",
      "      Args:\n",
      "        unused_dummy: Ignored value.\n",
      "\n",
      "      Returns:\n",
      "        A `tf.int64` tensor whose value uniquely identifies an iterator in\n",
      "        `generator_state`.\n",
      "      \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mscript_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                       \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mgenerator_next_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;34m\"\"\"Generates the next element from iterator with ID `iterator_id_t`.\n",
      "\n",
      "      We map this function across an infinite repetition of the\n",
      "      `iterator_id_t`, and raise `StopIteration` to terminate the iteration.\n",
      "\n",
      "      Args:\n",
      "        iterator_id_t: A `tf.int64` tensor whose value uniquely identifies the\n",
      "          iterator in `generator_state` from which to generate an element.\n",
      "\n",
      "      Returns:\n",
      "        The next element to generate from the iterator.\n",
      "      \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0moutput_types\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mflattened_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mflattened_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mdef\u001b[0m \u001b[0mgenerator_py_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34m\"\"\"A `py_func` that will be called to invoke the iterator.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# `next()` raises `StopIteration` when there are no more\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# elements remaining to be generated.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# Use the same _convert function from the py_func() implementation to\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# convert the returned values to arrays early, so that we can inspect\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# their values.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mflattened_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"`generator` yielded an element that did not match the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"expected structure. The expected structure was \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"{output_types}, but the yielded element was {values}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mret_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mfor\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflattened_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflattened_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0mret_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[0mscript_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFuncRegistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34mf\"`generator` yielded an element that could not be \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34mf\"converted to the expected type. The expected type was \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34mf\"{dtype.name}, but the yielded element was {ret}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# Additional type and shape checking to ensure that the components of\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# the generated element match the `output_types` and `output_shapes`\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# arguments.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mret_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mexpected_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflattened_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                      \u001b[0mflattened_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mret_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_dtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34mf\"`generator` yielded an element of type {ret_array.dtype} \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34mf\"where an element of type {expected_dtype.as_numpy_dtype} \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34mf\"was expected.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexpected_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34mf\"`generator` yielded an element of shape {ret_array.shape} \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                  \u001b[1;34mf\"where an element of shape {expected_shape} was expected.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mreturn\u001b[0m \u001b[0mret_arrays\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mflat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscript_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_py_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                \u001b[1;33m[\u001b[0m\u001b[0miterator_id_t\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                \u001b[0mflattened_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# In debug mode the numpy_function will return a scalar if\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# generator_py_func produces only a single value.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mflat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mflat_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# The `py_func()` op drops the inferred shapes, so we add them back in\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# here.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moutput_shapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mfor\u001b[0m \u001b[0mret_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflattened_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mret_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mflat_output_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_flat_tensor_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mdef\u001b[0m \u001b[0mgenerator_py_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34m\"\"\"A `py_func` that will be called to invoke the iterator.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# `next()` raises `StopIteration` when there are no more\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;31m# elements remaining to be generated.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"`generator` yielded an element that did not match the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"expected structure. The expected structure was \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"{output_signature}, but the yielded element was \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"{values}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mvalues_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mare_compatible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34mf\"`generator` yielded an element of {values_spec} where an \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34mf\"element of {output_signature} was expected.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mscript_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager_py_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mgenerator_py_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miterator_id_t\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_output_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mfinalize_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;34m\"\"\"Releases host-side state for the iterator with ID `iterator_id_t`.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mdef\u001b[0m \u001b[0mfinalize_py_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mgenerator_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterator_completed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# We return a dummy value so that the `finalize_fn` has a valid\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# signature.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# NOTE(mrry): Explicitly create an array of `np.int64` because implicit\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# casting in `py_func()` will create an array of `np.int32` on Windows,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# leading to a runtime error.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mscript_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalize_py_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0miterator_id_t\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                       \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# This function associates each traversal of `generator` with a unique\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# iterator ID.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mflat_map_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# The `get_iterator_id_fn` gets a unique ID for the current instance of\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# of the generator.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# The `generator_next_fn` gets the next element from the iterator with the\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# given ID, and raises StopIteration when that iterator contains no\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# more elements.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0m_GeneratorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mdummy_arg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mget_iterator_id_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mgenerator_next_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mfinalize_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0moutput_signature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# A single-element dataset that, each time it is evaluated, contains a\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# freshly-generated and unique (for the returned dataset) int64\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# ID that will be used to identify the appropriate Python state, which\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# is encapsulated in `generator_state`, and captured in\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# `get_iterator_id_map_fn`.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mid_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# A dataset that contains all of the elements generated by a\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# single iterator created from `generator`, identified by the\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# iterator ID contained in `id_dataset`. Lifting the iteration\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# into a flat_map here enables multiple repetitions and/or nested\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# versions of the returned dataset to be created, because it forces\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# the generation of a new ID for each version.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mid_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_map_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` of a step-separated range of values.\n",
      "\n",
      "    >>> list(Dataset.range(5).as_numpy_iterator())\n",
      "    [0, 1, 2, 3, 4]\n",
      "    >>> list(Dataset.range(2, 5).as_numpy_iterator())\n",
      "    [2, 3, 4]\n",
      "    >>> list(Dataset.range(1, 5, 2).as_numpy_iterator())\n",
      "    [1, 3]\n",
      "    >>> list(Dataset.range(1, 5, -2).as_numpy_iterator())\n",
      "    []\n",
      "    >>> list(Dataset.range(5, 1).as_numpy_iterator())\n",
      "    []\n",
      "    >>> list(Dataset.range(5, 1, -2).as_numpy_iterator())\n",
      "    [5, 3]\n",
      "    >>> list(Dataset.range(2, 5, output_type=tf.int32).as_numpy_iterator())\n",
      "    [2, 3, 4]\n",
      "    >>> list(Dataset.range(1, 5, 2, output_type=tf.float32).as_numpy_iterator())\n",
      "    [1.0, 3.0]\n",
      "\n",
      "    Args:\n",
      "      *args: follows the same semantics as python's range.\n",
      "        len(args) == 1 -> start = 0, stop = args[0], step = 1.\n",
      "        len(args) == 2 -> start = args[0], stop = args[1], step = 1.\n",
      "        len(args) == 3 -> start = args[0], stop = args[1], step = args[2].\n",
      "      **kwargs:\n",
      "        - output_type: Its expected dtype. (Optional, default: `tf.int64`).\n",
      "        - name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `RangeDataset`.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: if len(args) == 0.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mRangeDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` by zipping together the given datasets.\n",
      "\n",
      "    This method has similar semantics to the built-in `zip()` function\n",
      "    in Python, with the main difference being that the `datasets`\n",
      "    argument can be a (nested) structure of `Dataset` objects. The supported\n",
      "    nesting mechanisms are documented\n",
      "    [here] (https://www.tensorflow.org/guide/data#dataset_structure).\n",
      "\n",
      "    >>> # The nested structure of the `datasets` argument determines the\n",
      "    >>> # structure of elements in the resulting dataset.\n",
      "    >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      "    >>> b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
      "    >>> ds = tf.data.Dataset.zip((a, b))\n",
      "    >>> list(ds.as_numpy_iterator())\n",
      "    [(1, 4), (2, 5), (3, 6)]\n",
      "    >>> ds = tf.data.Dataset.zip((b, a))\n",
      "    >>> list(ds.as_numpy_iterator())\n",
      "    [(4, 1), (5, 2), (6, 3)]\n",
      "    >>>\n",
      "    >>> # The `datasets` argument may contain an arbitrary number of datasets.\n",
      "    >>> c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
      "    ...                                            #       [9, 10],\n",
      "    ...                                            #       [11, 12] ]\n",
      "    >>> ds = tf.data.Dataset.zip((a, b, c))\n",
      "    >>> for element in ds.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    (1, 4, array([7, 8]))\n",
      "    (2, 5, array([ 9, 10]))\n",
      "    (3, 6, array([11, 12]))\n",
      "    >>>\n",
      "    >>> # The number of elements in the resulting dataset is the same as\n",
      "    >>> # the size of the smallest dataset in `datasets`.\n",
      "    >>> d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\n",
      "    >>> ds = tf.data.Dataset.zip((a, d))\n",
      "    >>> list(ds.as_numpy_iterator())\n",
      "    [(1, 13), (2, 14)]\n",
      "\n",
      "    Args:\n",
      "      datasets: A (nested) structure of datasets.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mZipDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      "\n",
      "    >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      "    >>> b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ]\n",
      "    >>> ds = a.concatenate(b)\n",
      "    >>> list(ds.as_numpy_iterator())\n",
      "    [1, 2, 3, 4, 5, 6, 7]\n",
      "    >>> # The input dataset and dataset to be concatenated should have\n",
      "    >>> # compatible element specs.\n",
      "    >>> c = tf.data.Dataset.zip((a, b))\n",
      "    >>> a.concatenate(c)\n",
      "    Traceback (most recent call last):\n",
      "    TypeError: Two datasets to concatenate have different types\n",
      "    <dtype: 'int64'> and (tf.int64, tf.int64)\n",
      "    >>> d = tf.data.Dataset.from_tensor_slices([\"a\", \"b\", \"c\"])\n",
      "    >>> a.concatenate(d)\n",
      "    Traceback (most recent call last):\n",
      "    TypeError: Two datasets to concatenate have different types\n",
      "    <dtype: 'int64'> and <dtype: 'string'>\n",
      "\n",
      "    Args:\n",
      "      dataset: `Dataset` to be concatenated.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mConcatenateDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` that prefetches elements from this dataset.\n",
      "\n",
      "    Most dataset input pipelines should end with a call to `prefetch`. This\n",
      "    allows later elements to be prepared while the current element is being\n",
      "    processed. This often improves latency and throughput, at the cost of\n",
      "    using additional memory to store prefetched elements.\n",
      "\n",
      "    Note: Like other `Dataset` methods, prefetch operates on the\n",
      "    elements of the input dataset. It has no concept of examples vs. batches.\n",
      "    `examples.prefetch(2)` will prefetch two elements (2 examples),\n",
      "    while `examples.batch(20).prefetch(2)` will prefetch 2 elements\n",
      "    (2 batches, of 20 examples each).\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(3)\n",
      "    >>> dataset = dataset.prefetch(2)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [0, 1, 2]\n",
      "\n",
      "    Args:\n",
      "      buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the maximum\n",
      "        number of elements that will be buffered when prefetching. If the value\n",
      "        `tf.data.AUTOTUNE` is used, then the buffer size is dynamically tuned.\n",
      "      name: Optional. A name for the tf.data transformation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mPrefetchDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mlist_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"A dataset of all files matching one or more glob patterns.\n",
      "\n",
      "    The `file_pattern` argument should be a small number of glob patterns.\n",
      "    If your filenames have already been globbed, use\n",
      "    `Dataset.from_tensor_slices(filenames)` instead, as re-globbing every\n",
      "    filename with `list_files` may result in poor performance with remote\n",
      "    storage systems.\n",
      "\n",
      "    Note: The default behavior of this method is to return filenames in\n",
      "    a non-deterministic random shuffled order. Pass a `seed` or `shuffle=False`\n",
      "    to get results in a deterministic order.\n",
      "\n",
      "    Example:\n",
      "      If we had the following files on our filesystem:\n",
      "\n",
      "        - /path/to/dir/a.txt\n",
      "        - /path/to/dir/b.py\n",
      "        - /path/to/dir/c.py\n",
      "\n",
      "      If we pass \"/path/to/dir/*.py\" as the directory, the dataset\n",
      "      would produce:\n",
      "\n",
      "        - /path/to/dir/b.py\n",
      "        - /path/to/dir/c.py\n",
      "\n",
      "    Args:\n",
      "      file_pattern: A string, a list of strings, or a `tf.Tensor` of string type\n",
      "        (scalar or vector), representing the filename glob (i.e. shell wildcard)\n",
      "        pattern(s) that will be matched.\n",
      "      shuffle: (Optional.) If `True`, the file names will be shuffled randomly.\n",
      "        Defaults to `True`.\n",
      "      seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      "        seed that will be used to create the distribution. See\n",
      "        `tf.random.set_seed` for behavior.\n",
      "      name: Optional. A name for the tf.data operations used by `list_files`.\n",
      "\n",
      "    Returns:\n",
      "     Dataset: A `Dataset` of strings corresponding to file names.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"list_files\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mfile_pattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mfile_pattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"file_pattern\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mmatching_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# Raise an exception if `file_pattern` does not match any files.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mcondition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                   \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"match_not_empty\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34m\"No files matched pattern: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mstring_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_join\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\", \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0massert_not_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAssert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"assert_not_empty\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmatching_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetV1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# NOTE(mrry): The shuffle buffer size must be greater than zero, but the\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# list of files might be empty.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mbuffer_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Repeats this dataset so each original value is seen `count` times.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> dataset = dataset.repeat(3)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
      "\n",
      "    Note: If the input dataset depends on global state (e.g. a random number\n",
      "    generator) or its output is non-deterministic (e.g. because of upstream\n",
      "    `shuffle`), then different repetitions may produce different elements.\n",
      "\n",
      "    Args:\n",
      "      count: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      "        number of times the dataset should be repeated. The default behavior (if\n",
      "        `count` is `None` or `-1`) is for the dataset be repeated indefinitely.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mRepeatDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Enumerates the elements of this dataset.\n",
      "\n",
      "    It is similar to python's `enumerate`.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> dataset = dataset.enumerate(start=5)\n",
      "    >>> for element in dataset.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    (5, 1)\n",
      "    (6, 2)\n",
      "    (7, 3)\n",
      "\n",
      "    >>> # The (nested) structure of the input dataset determines the\n",
      "    >>> # structure of elements in the resulting dataset.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)])\n",
      "    >>> dataset = dataset.enumerate()\n",
      "    >>> for element in dataset.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    (0, array([7, 8], dtype=int32))\n",
      "    (1, array([ 9, 10], dtype=int32))\n",
      "\n",
      "    Args:\n",
      "      start: A `tf.int64` scalar `tf.Tensor`, representing the start value for\n",
      "        enumeration.\n",
      "      name: Optional. A name for the tf.data operations used by `enumerate`.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrange_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Replicate the range component so that each split is enumerated\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# independently. This avoids the need for prohibitively expensive\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# cross-split coordination.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrange_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_apply_rewrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"replicate_on_split\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0mreshuffle_each_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Randomly shuffles the elements of this dataset.\n",
      "\n",
      "    This dataset fills a buffer with `buffer_size` elements, then randomly\n",
      "    samples elements from this buffer, replacing the selected elements with new\n",
      "    elements. For perfect shuffling, a buffer size greater than or equal to the\n",
      "    full size of the dataset is required.\n",
      "\n",
      "    For instance, if your dataset contains 10,000 elements but `buffer_size` is\n",
      "    set to 1,000, then `shuffle` will initially select a random element from\n",
      "    only the first 1,000 elements in the buffer. Once an element is selected,\n",
      "    its space in the buffer is replaced by the next (i.e. 1,001-st) element,\n",
      "    maintaining the 1,000 element buffer.\n",
      "\n",
      "    `reshuffle_each_iteration` controls whether the shuffle order should be\n",
      "    different for each epoch. In TF 1.X, the idiomatic way to create epochs\n",
      "    was through the `repeat` transformation:\n",
      "\n",
      "    ```python\n",
      "    dataset = tf.data.Dataset.range(3)\n",
      "    dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      "    dataset = dataset.repeat(2)\n",
      "    # [1, 0, 2, 1, 2, 0]\n",
      "\n",
      "    dataset = tf.data.Dataset.range(3)\n",
      "    dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      "    dataset = dataset.repeat(2)\n",
      "    # [1, 0, 2, 1, 0, 2]\n",
      "    ```\n",
      "\n",
      "    In TF 2.0, `tf.data.Dataset` objects are Python iterables which makes it\n",
      "    possible to also create epochs through Python iteration:\n",
      "\n",
      "    ```python\n",
      "    dataset = tf.data.Dataset.range(3)\n",
      "    dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      "    list(dataset.as_numpy_iterator())\n",
      "    # [1, 0, 2]\n",
      "    list(dataset.as_numpy_iterator())\n",
      "    # [1, 2, 0]\n",
      "    ```\n",
      "\n",
      "    ```python\n",
      "    dataset = tf.data.Dataset.range(3)\n",
      "    dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      "    list(dataset.as_numpy_iterator())\n",
      "    # [1, 0, 2]\n",
      "    list(dataset.as_numpy_iterator())\n",
      "    # [1, 0, 2]\n",
      "    ```\n",
      "\n",
      "    Args:\n",
      "      buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      "        elements from this dataset from which the new dataset will sample.\n",
      "      seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      "        seed that will be used to create the distribution. See\n",
      "        `tf.random.set_seed` for behavior.\n",
      "      reshuffle_each_iteration: (Optional.) A boolean, which if true indicates\n",
      "        that the dataset should be pseudorandomly reshuffled each time it is\n",
      "        iterated over. (Defaults to `True`.)\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mShuffleDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreshuffle_each_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Caches the elements in this dataset.\n",
      "\n",
      "    The first time the dataset is iterated over, its elements will be cached\n",
      "    either in the specified file or in memory. Subsequent iterations will\n",
      "    use the cached data.\n",
      "\n",
      "    Note: To guarantee that the cache gets finalized, the input dataset must be\n",
      "    iterated through in its entirety, until it raises StopIteration. Otherwise,\n",
      "    subsequent iterations may not use cached data.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(5)\n",
      "    >>> dataset = dataset.map(lambda x: x**2)\n",
      "    >>> dataset = dataset.cache()\n",
      "    >>> # The first time reading through the data will generate the data using\n",
      "    >>> # `range` and `map`.\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [0, 1, 4, 9, 16]\n",
      "    >>> # Subsequent iterations read from the cache.\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [0, 1, 4, 9, 16]\n",
      "\n",
      "    When caching to a file, the cached data will persist across runs. Even the\n",
      "    first iteration through the data will read from the cache file. Changing\n",
      "    the input pipeline before the call to `.cache()` will have no effect until\n",
      "    the cache file is removed or the filename is changed.\n",
      "\n",
      "    ```python\n",
      "    dataset = tf.data.Dataset.range(5)\n",
      "    dataset = dataset.cache(\"/path/to/file\")\n",
      "    list(dataset.as_numpy_iterator())\n",
      "    # [0, 1, 2, 3, 4]\n",
      "    dataset = tf.data.Dataset.range(10)\n",
      "    dataset = dataset.cache(\"/path/to/file\")  # Same file!\n",
      "    list(dataset.as_numpy_iterator())\n",
      "    # [0, 1, 2, 3, 4]\n",
      "    ```\n",
      "\n",
      "    Note: `cache` will produce exactly the same elements during each iteration\n",
      "    through the dataset. If you wish to randomize the iteration order, make sure\n",
      "    to call `shuffle` *after* calling `cache`.\n",
      "\n",
      "    Args:\n",
      "      filename: A `tf.string` scalar `tf.Tensor`, representing the name of a\n",
      "        directory on the filesystem to use for caching elements in this Dataset.\n",
      "        If a filename is not provided, the dataset will be cached in memory.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mCacheDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` with at most `count` elements from this dataset.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(10)\n",
      "    >>> dataset = dataset.take(3)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [0, 1, 2]\n",
      "\n",
      "    Args:\n",
      "      count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      "        elements of this dataset that should be taken to form the new dataset.\n",
      "        If `count` is -1, or if `count` is greater than the size of this\n",
      "        dataset, the new dataset will contain all elements of this dataset.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mTakeDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mskip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` that skips `count` elements from this dataset.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(10)\n",
      "    >>> dataset = dataset.skip(7)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [7, 8, 9]\n",
      "\n",
      "    Args:\n",
      "      count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      "        elements of this dataset that should be skipped to form the new dataset.\n",
      "        If `count` is greater than the size of this dataset, the new dataset\n",
      "        will contain no elements.  If `count` is -1, skips the entire dataset.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mSkipDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mshard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      "\n",
      "    `shard` is deterministic. The Dataset produced by `A.shard(n, i)` will\n",
      "    contain all elements of A whose index mod n = i.\n",
      "\n",
      "    >>> A = tf.data.Dataset.range(10)\n",
      "    >>> B = A.shard(num_shards=3, index=0)\n",
      "    >>> list(B.as_numpy_iterator())\n",
      "    [0, 3, 6, 9]\n",
      "    >>> C = A.shard(num_shards=3, index=1)\n",
      "    >>> list(C.as_numpy_iterator())\n",
      "    [1, 4, 7]\n",
      "    >>> D = A.shard(num_shards=3, index=2)\n",
      "    >>> list(D.as_numpy_iterator())\n",
      "    [2, 5, 8]\n",
      "\n",
      "    This dataset operator is very useful when running distributed training, as\n",
      "    it allows each worker to read a unique subset.\n",
      "\n",
      "    When reading a single input file, you can shard elements as follows:\n",
      "\n",
      "    ```python\n",
      "    d = tf.data.TFRecordDataset(input_file)\n",
      "    d = d.shard(num_workers, worker_index)\n",
      "    d = d.repeat(num_epochs)\n",
      "    d = d.shuffle(shuffle_buffer_size)\n",
      "    d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      "    ```\n",
      "\n",
      "    Important caveats:\n",
      "\n",
      "    - Be sure to shard before you use any randomizing operator (such as\n",
      "      shuffle).\n",
      "    - Generally it is best if the shard operator is used early in the dataset\n",
      "      pipeline. For example, when reading from a set of TFRecord files, shard\n",
      "      before converting the dataset to input samples. This avoids reading every\n",
      "      file on every worker. The following is an example of an efficient\n",
      "      sharding strategy within a complete pipeline:\n",
      "\n",
      "    ```python\n",
      "    d = Dataset.list_files(pattern)\n",
      "    d = d.shard(num_workers, worker_index)\n",
      "    d = d.repeat(num_epochs)\n",
      "    d = d.shuffle(shuffle_buffer_size)\n",
      "    d = d.interleave(tf.data.TFRecordDataset,\n",
      "                     cycle_length=num_readers, block_length=1)\n",
      "    d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      "    ```\n",
      "\n",
      "    Args:\n",
      "      num_shards: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      "        shards operating in parallel.\n",
      "      index: A `tf.int64` scalar `tf.Tensor`, representing the worker index.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "\n",
      "    Raises:\n",
      "      InvalidArgumentError: if `num_shards` or `index` are illegal values.\n",
      "\n",
      "        Note: error checking is done on a best-effort basis, and errors aren't\n",
      "        guaranteed to be caught upon dataset creation. (e.g. providing in a\n",
      "        placeholder tensor bypasses the early checking, and will instead result\n",
      "        in an error during a session.run call.)\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mShardDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m           \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m           \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m           \u001b[0mshard_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m           \u001b[0mcheckpoint_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Saves the content of the given dataset.\n",
      "\n",
      "      Example usage:\n",
      "\n",
      "      >>> import tempfile\n",
      "      >>> path = os.path.join(tempfile.gettempdir(), \"saved_data\")\n",
      "      >>> # Save a dataset\n",
      "      >>> dataset = tf.data.Dataset.range(2)\n",
      "      >>> dataset.save(path)\n",
      "      >>> new_dataset = tf.data.Dataset.load(path)\n",
      "      >>> for elem in new_dataset:\n",
      "      ...   print(elem)\n",
      "      tf.Tensor(0, shape=(), dtype=int64)\n",
      "      tf.Tensor(1, shape=(), dtype=int64)\n",
      "\n",
      "      The saved dataset is saved in multiple file \"shards\". By default, the\n",
      "      dataset output is divided to shards in a round-robin fashion but custom\n",
      "      sharding can be specified via the `shard_func` function. For example, you\n",
      "      can save the dataset to using a single shard as follows:\n",
      "\n",
      "      ```python\n",
      "      dataset = make_dataset()\n",
      "      def custom_shard_func(element):\n",
      "        return np.int64(0)\n",
      "      dataset.save(\n",
      "          path=\"/path/to/data\", ..., shard_func=custom_shard_func)\n",
      "      ```\n",
      "\n",
      "      To enable checkpointing, pass in `checkpoint_args` to the `save` method\n",
      "      as follows:\n",
      "\n",
      "      ```python\n",
      "      dataset = tf.data.Dataset.range(100)\n",
      "      save_dir = \"...\"\n",
      "      checkpoint_prefix = \"...\"\n",
      "      step_counter = tf.Variable(0, trainable=False)\n",
      "      checkpoint_args = {\n",
      "        \"checkpoint_interval\": 50,\n",
      "        \"step_counter\": step_counter,\n",
      "        \"directory\": checkpoint_prefix,\n",
      "        \"max_to_keep\": 20,\n",
      "      }\n",
      "      dataset.save(dataset, save_dir, checkpoint_args=checkpoint_args)\n",
      "      ```\n",
      "\n",
      "      NOTE: The directory layout and file format used for saving the dataset is\n",
      "      considered an implementation detail and may change. For this reason,\n",
      "      datasets saved through `tf.data.Dataset.save` should only be consumed\n",
      "      through `tf.data.Dataset.load`, which is guaranteed to be\n",
      "      backwards compatible.\n",
      "\n",
      "    Args:\n",
      "     path: Required. A directory to use for saving the dataset.\n",
      "     compression: Optional. The algorithm to use to compress data when writing\n",
      "          it. Supported options are `GZIP` and `NONE`. Defaults to `NONE`.\n",
      "     shard_func: Optional. A function to control the mapping of dataset\n",
      "          elements to file shards. The function is expected to map elements of\n",
      "          the input dataset to int64 shard IDs. If present, the function will be\n",
      "          traced and executed as graph computation.\n",
      "     checkpoint_args: Optional args for checkpointing which will be passed into\n",
      "          the `tf.train.CheckpointManager`. If `checkpoint_args` are not\n",
      "          specified, then checkpointing will not be performed. The `save()`\n",
      "          implementation creates a `tf.train.Checkpoint` object internally, so\n",
      "          users should not set the `checkpoint` argument in `checkpoint_args`.\n",
      "\n",
      "    Raises:\n",
      "      ValueError if `checkpoint` is passed into `checkpoint_args`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Loaded lazily due to a circular dependency\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# dataset_ops->save_ops->dataset_ops\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_op\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msave_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshard_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Loads a previously saved dataset.\n",
      "\n",
      "    Example usage:\n",
      "\n",
      "    >>> import tempfile\n",
      "    >>> path = os.path.join(tempfile.gettempdir(), \"saved_data\")\n",
      "    >>> # Save a dataset\n",
      "    >>> dataset = tf.data.Dataset.range(2)\n",
      "    >>> tf.data.Dataset.save(dataset, path)\n",
      "    >>> new_dataset = tf.data.Dataset.load(path)\n",
      "    >>> for elem in new_dataset:\n",
      "    ...   print(elem)\n",
      "    tf.Tensor(0, shape=(), dtype=int64)\n",
      "    tf.Tensor(1, shape=(), dtype=int64)\n",
      "\n",
      "\n",
      "    If the default option of sharding the saved dataset was used, the element\n",
      "    order of the saved dataset will be preserved when loading it.\n",
      "\n",
      "    The `reader_func` argument can be used to specify a custom order in which\n",
      "    elements should be loaded from the individual shards. The `reader_func` is\n",
      "    expected to take a single argument -- a dataset of datasets, each containing\n",
      "    elements of one of the shards -- and return a dataset of elements. For\n",
      "    example, the order of shards can be shuffled when loading them as follows:\n",
      "\n",
      "    ```python\n",
      "    def custom_reader_func(datasets):\n",
      "      datasets = datasets.shuffle(NUM_SHARDS)\n",
      "      return datasets.interleave(lambda x: x, num_parallel_calls=AUTOTUNE)\n",
      "\n",
      "    dataset = tf.data.Dataset.load(\n",
      "        path=\"/path/to/data\", ..., reader_func=custom_reader_func)\n",
      "    ```\n",
      "\n",
      "    Args:\n",
      "      path: Required. A path pointing to a previously saved dataset.\n",
      "      element_spec: Optional. A nested structure of `tf.TypeSpec` objects\n",
      "        matching the structure of an element of the saved dataset and specifying\n",
      "        the type of individual element components. If not provided, the nested\n",
      "        structure of `tf.TypeSpec` saved with the saved dataset is used. Note\n",
      "        that this argument is required in graph mode.\n",
      "      compression: Optional. The algorithm to use to decompress the data when\n",
      "        reading it. Supported options are `GZIP` and `NONE`. Defaults to `NONE`.\n",
      "      reader_func: Optional. A function to control how to read data from shards.\n",
      "        If present, the function will be traced and executed as graph\n",
      "        computation.\n",
      "\n",
      "    Returns:\n",
      "      A `tf.data.Dataset` instance.\n",
      "\n",
      "    Raises:\n",
      "      FileNotFoundError: If `element_spec` is not specified and the saved nested\n",
      "        structure of `tf.TypeSpec` can not be located with the saved dataset.\n",
      "      ValueError: If `element_spec` is not specified and the method is executed\n",
      "        in graph mode.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Loaded lazily due to a circular dependency\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# dataset_ops->load_ops->dataset_ops\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_op\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mload_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0melement_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mreader_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreader_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Combines consecutive elements of this dataset into batches.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(8)\n",
      "    >>> dataset = dataset.batch(3)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(8)\n",
      "    >>> dataset = dataset.batch(3, drop_remainder=True)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([0, 1, 2]), array([3, 4, 5])]\n",
      "\n",
      "    The components of the resulting element will have an additional outer\n",
      "    dimension, which will be `batch_size` (or `N % batch_size` for the last\n",
      "    element if `batch_size` does not divide the number of input elements `N`\n",
      "    evenly and `drop_remainder` is `False`). If your program depends on the\n",
      "    batches having the same outer dimension, you should set the `drop_remainder`\n",
      "    argument to `True` to prevent the smaller batch from being produced.\n",
      "\n",
      "    Note: If your program requires data to have a statically known shape (e.g.,\n",
      "    when using XLA), you should use `drop_remainder=True`. Without\n",
      "    `drop_remainder=True` the shape of the output dataset will have an unknown\n",
      "    leading dimension due to the possibility of a smaller final batch.\n",
      "\n",
      "    Args:\n",
      "      batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      "        consecutive elements of this dataset to combine in a single batch.\n",
      "      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      "        whether the last batch should be dropped in the case it has fewer than\n",
      "        `batch_size` elements; the default behavior is not to drop the smaller\n",
      "        batch.\n",
      "      num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      "        representing the number of batches to compute asynchronously in\n",
      "        parallel.\n",
      "        If not specified, batches will be computed sequentially. If the value\n",
      "        `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      "        calls is set dynamically based on available resources.\n",
      "      deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      "        boolean is specified (`True` or `False`), it controls the order in which\n",
      "        the transformation produces elements. If set to `False`, the\n",
      "        transformation is allowed to yield elements out of order to trade\n",
      "        determinism for performance. If not specified, the\n",
      "        `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      "        behavior.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The `deterministic` argument has no effect unless the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34m\"`num_parallel_calls` argument is specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mBatchDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mParallelBatchDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mdeterministic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mpadded_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                   \u001b[0mpadded_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                   \u001b[0mpadding_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                   \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                   \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Combines consecutive elements of this dataset into padded batches.\n",
      "\n",
      "    This transformation combines multiple consecutive elements of the input\n",
      "    dataset into a single element.\n",
      "\n",
      "    Like `tf.data.Dataset.batch`, the components of the resulting element will\n",
      "    have an additional outer dimension, which will be `batch_size` (or\n",
      "    `N % batch_size` for the last element if `batch_size` does not divide the\n",
      "    number of input elements `N` evenly and `drop_remainder` is `False`). If\n",
      "    your program depends on the batches having the same outer dimension, you\n",
      "    should set the `drop_remainder` argument to `True` to prevent the smaller\n",
      "    batch from being produced.\n",
      "\n",
      "    Unlike `tf.data.Dataset.batch`, the input elements to be batched may have\n",
      "    different shapes, and this transformation will pad each component to the\n",
      "    respective shape in `padded_shapes`. The `padded_shapes` argument\n",
      "    determines the resulting shape for each dimension of each component in an\n",
      "    output element:\n",
      "\n",
      "    * If the dimension is a constant, the component will be padded out to that\n",
      "      length in that dimension.\n",
      "    * If the dimension is unknown, the component will be padded out to the\n",
      "      maximum length of all elements in that dimension.\n",
      "\n",
      "    >>> A = (tf.data.Dataset\n",
      "    ...      .range(1, 5, output_type=tf.int32)\n",
      "    ...      .map(lambda x: tf.fill([x], x)))\n",
      "    >>> # Pad to the smallest per-batch size that fits all elements.\n",
      "    >>> B = A.padded_batch(2)\n",
      "    >>> for element in B.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    [[1 0]\n",
      "     [2 2]]\n",
      "    [[3 3 3 0]\n",
      "     [4 4 4 4]]\n",
      "    >>> # Pad to a fixed size.\n",
      "    >>> C = A.padded_batch(2, padded_shapes=5)\n",
      "    >>> for element in C.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    [[1 0 0 0 0]\n",
      "     [2 2 0 0 0]]\n",
      "    [[3 3 3 0 0]\n",
      "     [4 4 4 4 0]]\n",
      "    >>> # Pad with a custom value.\n",
      "    >>> D = A.padded_batch(2, padded_shapes=5, padding_values=-1)\n",
      "    >>> for element in D.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    [[ 1 -1 -1 -1 -1]\n",
      "     [ 2  2 -1 -1 -1]]\n",
      "    [[ 3  3  3 -1 -1]\n",
      "     [ 4  4  4  4 -1]]\n",
      "    >>> # Components of nested elements can be padded independently.\n",
      "    >>> elements = [([1, 2, 3], [10]),\n",
      "    ...             ([4, 5], [11, 12])]\n",
      "    >>> dataset = tf.data.Dataset.from_generator(\n",
      "    ...     lambda: iter(elements), (tf.int32, tf.int32))\n",
      "    >>> # Pad the first component of the tuple to length 4, and the second\n",
      "    >>> # component to the smallest size that fits.\n",
      "    >>> dataset = dataset.padded_batch(2,\n",
      "    ...     padded_shapes=([4], [None]),\n",
      "    ...     padding_values=(-1, 100))\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [(array([[ 1,  2,  3, -1], [ 4,  5, -1, -1]], dtype=int32),\n",
      "      array([[ 10, 100], [ 11,  12]], dtype=int32))]\n",
      "    >>> # Pad with a single value and multiple components.\n",
      "    >>> E = tf.data.Dataset.zip((A, A)).padded_batch(2, padding_values=-1)\n",
      "    >>> for element in E.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    (array([[ 1, -1],\n",
      "           [ 2,  2]], dtype=int32), array([[ 1, -1],\n",
      "           [ 2,  2]], dtype=int32))\n",
      "    (array([[ 3,  3,  3, -1],\n",
      "           [ 4,  4,  4,  4]], dtype=int32), array([[ 3,  3,  3, -1],\n",
      "           [ 4,  4,  4,  4]], dtype=int32))\n",
      "\n",
      "    See also `tf.data.experimental.dense_to_sparse_batch`, which combines\n",
      "    elements that may have different shapes into a `tf.sparse.SparseTensor`.\n",
      "\n",
      "    Args:\n",
      "      batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      "        consecutive elements of this dataset to combine in a single batch.\n",
      "      padded_shapes: (Optional.) A (nested) structure of `tf.TensorShape` or\n",
      "        `tf.int64` vector tensor-like objects representing the shape to which\n",
      "        the respective component of each input element should be padded prior\n",
      "        to batching. Any unknown dimensions will be padded to the maximum size\n",
      "        of that dimension in each batch. If unset, all dimensions of all\n",
      "        components are padded to the maximum size in the batch. `padded_shapes`\n",
      "        must be set if any component has an unknown rank.\n",
      "      padding_values: (Optional.) A (nested) structure of scalar-shaped\n",
      "        `tf.Tensor`, representing the padding values to use for the respective\n",
      "        components. None represents that the (nested) structure should be padded\n",
      "        with default values.  Defaults are `0` for numeric types and the empty\n",
      "        string for string types. The `padding_values` should have the same\n",
      "        (nested) structure as the input dataset. If `padding_values` is a single\n",
      "        element and the input dataset has multiple components, then the same\n",
      "        `padding_values` will be used to pad every component of the dataset.\n",
      "        If `padding_values` is a scalar, then its value will be broadcasted\n",
      "        to match the shape of each component.\n",
      "      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      "        whether the last batch should be dropped in the case it has fewer than\n",
      "        `batch_size` elements; the default behavior is not to drop the smaller\n",
      "        batch.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: If a component has an unknown rank, and the `padded_shapes`\n",
      "        argument is not set.\n",
      "      TypeError: If a component is of an unsupported type. The list of supported\n",
      "        types is documented in\n",
      "        https://www.tensorflow.org/guide/data#dataset_structure.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mpadded_shapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mpadded_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_legacy_output_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# A `tf.TensorShape` is only false if its *rank* is unknown.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"You must provide `padded_shapes` argument because \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                           \u001b[1;34mf\"component {i} has unknown rank.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mPaddedBatchDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpadded_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpadding_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Maps `map_func` across the elements of this dataset.\n",
      "\n",
      "    This transformation applies `map_func` to each element of this dataset, and\n",
      "    returns a new dataset containing the transformed elements, in the same\n",
      "    order as they appeared in the input. `map_func` can be used to change both\n",
      "    the values and the structure of a dataset's elements. Supported structure\n",
      "    constructs are documented\n",
      "    [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      "\n",
      "    For example, `map` can be used for adding 1 to each element, or projecting a\n",
      "    subset of element components.\n",
      "\n",
      "    >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      "    >>> dataset = dataset.map(lambda x: x + 1)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [2, 3, 4, 5, 6]\n",
      "\n",
      "    The input signature of `map_func` is determined by the structure of each\n",
      "    element in this dataset.\n",
      "\n",
      "    >>> dataset = Dataset.range(5)\n",
      "    >>> # `map_func` takes a single argument of type `tf.Tensor` with the same\n",
      "    >>> # shape and dtype.\n",
      "    >>> result = dataset.map(lambda x: x + 1)\n",
      "\n",
      "    >>> # Each element is a tuple containing two `tf.Tensor` objects.\n",
      "    >>> elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz\")]\n",
      "    >>> dataset = tf.data.Dataset.from_generator(\n",
      "    ...     lambda: elements, (tf.int32, tf.string))\n",
      "    >>> # `map_func` takes two arguments of type `tf.Tensor`. This function\n",
      "    >>> # projects out just the first component.\n",
      "    >>> result = dataset.map(lambda x_int, y_str: x_int)\n",
      "    >>> list(result.as_numpy_iterator())\n",
      "    [1, 2, 3]\n",
      "\n",
      "    >>> # Each element is a dictionary mapping strings to `tf.Tensor` objects.\n",
      "    >>> elements =  ([{\"a\": 1, \"b\": \"foo\"},\n",
      "    ...               {\"a\": 2, \"b\": \"bar\"},\n",
      "    ...               {\"a\": 3, \"b\": \"baz\"}])\n",
      "    >>> dataset = tf.data.Dataset.from_generator(\n",
      "    ...     lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
      "    >>> # `map_func` takes a single argument of type `dict` with the same keys\n",
      "    >>> # as the elements.\n",
      "    >>> result = dataset.map(lambda d: str(d[\"a\"]) + d[\"b\"])\n",
      "\n",
      "    The value or values returned by `map_func` determine the structure of each\n",
      "    element in the returned dataset.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(3)\n",
      "    >>> # `map_func` returns two `tf.Tensor` objects.\n",
      "    >>> def g(x):\n",
      "    ...   return tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])\n",
      "    >>> result = dataset.map(g)\n",
      "    >>> result.element_spec\n",
      "    (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(3,), \\\n",
      "dtype=tf.string, name=None))\n",
      "    >>> # Python primitives, lists, and NumPy arrays are implicitly converted to\n",
      "    >>> # `tf.Tensor`.\n",
      "    >>> def h(x):\n",
      "    ...   return 37.0, [\"Foo\", \"Bar\"], np.array([1.0, 2.0], dtype=np.float64)\n",
      "    >>> result = dataset.map(h)\n",
      "    >>> result.element_spec\n",
      "    (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(2,), \\\n",
      "dtype=tf.string, name=None), TensorSpec(shape=(2,), dtype=tf.float64, \\\n",
      "name=None))\n",
      "    >>> # `map_func` can return nested structures.\n",
      "    >>> def i(x):\n",
      "    ...   return (37.0, [42, 16]), \"foo\"\n",
      "    >>> result = dataset.map(i)\n",
      "    >>> result.element_spec\n",
      "    ((TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
      "      TensorSpec(shape=(2,), dtype=tf.int32, name=None)),\n",
      "     TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      "\n",
      "    `map_func` can accept as arguments and return any type of dataset element.\n",
      "\n",
      "    Note that irrespective of the context in which `map_func` is defined (eager\n",
      "    vs. graph), tf.data traces the function and executes it as a graph. To use\n",
      "    Python code inside of the function you have a few options:\n",
      "\n",
      "    1) Rely on AutoGraph to convert Python code into an equivalent graph\n",
      "    computation. The downside of this approach is that AutoGraph can convert\n",
      "    some but not all Python code.\n",
      "\n",
      "    2) Use `tf.py_function`, which allows you to write arbitrary Python code but\n",
      "    will generally result in worse performance than 1). For example:\n",
      "\n",
      "    >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      "    >>> # transform a string tensor to upper case string using a Python function\n",
      "    >>> def upper_case_fn(t: tf.Tensor):\n",
      "    ...   return t.numpy().decode('utf-8').upper()\n",
      "    >>> d = d.map(lambda x: tf.py_function(func=upper_case_fn,\n",
      "    ...           inp=[x], Tout=tf.string))\n",
      "    >>> list(d.as_numpy_iterator())\n",
      "    [b'HELLO', b'WORLD']\n",
      "\n",
      "    3) Use `tf.numpy_function`, which also allows you to write arbitrary\n",
      "    Python code. Note that `tf.py_function` accepts `tf.Tensor` whereas\n",
      "    `tf.numpy_function` accepts numpy arrays and returns only numpy arrays.\n",
      "    For example:\n",
      "\n",
      "    >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      "    >>> def upper_case_fn(t: np.ndarray):\n",
      "    ...   return t.decode('utf-8').upper()\n",
      "    >>> d = d.map(lambda x: tf.numpy_function(func=upper_case_fn,\n",
      "    ...           inp=[x], Tout=tf.string))\n",
      "    >>> list(d.as_numpy_iterator())\n",
      "    [b'HELLO', b'WORLD']\n",
      "\n",
      "    Note that the use of `tf.numpy_function` and `tf.py_function`\n",
      "    in general precludes the possibility of executing user-defined\n",
      "    transformations in parallel (because of Python GIL).\n",
      "\n",
      "    Performance can often be improved by setting `num_parallel_calls` so that\n",
      "    `map` will use multiple threads to process elements. If deterministic order\n",
      "    isn't required, it can also improve performance to set\n",
      "    `deterministic=False`.\n",
      "\n",
      "    >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      "    >>> dataset = dataset.map(lambda x: x + 1,\n",
      "    ...     num_parallel_calls=tf.data.AUTOTUNE,\n",
      "    ...     deterministic=False)\n",
      "\n",
      "    The order of elements yielded by this transformation is deterministic if\n",
      "    `deterministic=True`. If `map_func` contains stateful operations and\n",
      "    `num_parallel_calls > 1`, the order in which that state is accessed is\n",
      "    undefined, so the values of output elements may not be deterministic\n",
      "    regardless of the `deterministic` flag value.\n",
      "\n",
      "    Args:\n",
      "      map_func: A function mapping a dataset element to another dataset element.\n",
      "      num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      "        representing the number elements to process asynchronously in parallel.\n",
      "        If not specified, elements will be processed sequentially. If the value\n",
      "        `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      "        calls is set dynamically based on available CPU.\n",
      "      deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      "        boolean is specified (`True` or `False`), it controls the order in which\n",
      "        the transformation produces elements. If set to `False`, the\n",
      "        transformation is allowed to yield elements out of order to trade\n",
      "        determinism for performance. If not specified, the\n",
      "        `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      "        behavior.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The `deterministic` argument has no effect unless the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34m\"`num_parallel_calls` argument is specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mdeterministic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Maps `map_func` across this dataset and flattens the result.\n",
      "\n",
      "    The type signature is:\n",
      "\n",
      "    ```\n",
      "    def flat_map(\n",
      "      self: Dataset[T],\n",
      "      map_func: Callable[[T], Dataset[S]]\n",
      "    ) -> Dataset[S]\n",
      "    ```\n",
      "\n",
      "    Use `flat_map` if you want to make sure that the order of your dataset\n",
      "    stays the same. For example, to flatten a dataset of batches into a\n",
      "    dataset of their elements:\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(\n",
      "    ...     [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "    >>> dataset = dataset.flat_map(tf.data.Dataset.from_tensor_slices)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "    `tf.data.Dataset.interleave()` is a generalization of `flat_map`, since\n",
      "    `flat_map` produces the same output as\n",
      "    `tf.data.Dataset.interleave(cycle_length=1)`\n",
      "\n",
      "    Args:\n",
      "      map_func: A function mapping a dataset element to a dataset.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0minterleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                 \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                 \u001b[0mcycle_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                 \u001b[0mblock_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                 \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                 \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Maps `map_func` across this dataset, and interleaves the results.\n",
      "\n",
      "    The type signature is:\n",
      "\n",
      "    ```\n",
      "    def interleave(\n",
      "      self: Dataset[T],\n",
      "      map_func: Callable[[T], Dataset[S]]\n",
      "    ) -> Dataset[S]\n",
      "    ```\n",
      "\n",
      "    For example, you can use `Dataset.interleave()` to process many input files\n",
      "    concurrently:\n",
      "\n",
      "    >>> # Preprocess 4 files concurrently, and interleave blocks of 16 records\n",
      "    >>> # from each file.\n",
      "    >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      "    ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      "    >>> def parse_fn(filename):\n",
      "    ...   return tf.data.Dataset.range(10)\n",
      "    >>> dataset = dataset.interleave(lambda x:\n",
      "    ...     tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1),\n",
      "    ...     cycle_length=4, block_length=16)\n",
      "\n",
      "    The `cycle_length` and `block_length` arguments control the order in which\n",
      "    elements are produced. `cycle_length` controls the number of input elements\n",
      "    that are processed concurrently. If you set `cycle_length` to 1, this\n",
      "    transformation will handle one input element at a time, and will produce\n",
      "    identical results to `tf.data.Dataset.flat_map`. In general,\n",
      "    this transformation will apply `map_func` to `cycle_length` input elements,\n",
      "    open iterators on the returned `Dataset` objects, and cycle through them\n",
      "    producing `block_length` consecutive elements from each iterator, and\n",
      "    consuming the next input element each time it reaches the end of an\n",
      "    iterator.\n",
      "\n",
      "    For example:\n",
      "\n",
      "    >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      "    >>> # NOTE: New lines indicate \"block\" boundaries.\n",
      "    >>> dataset = dataset.interleave(\n",
      "    ...     lambda x: Dataset.from_tensors(x).repeat(6),\n",
      "    ...     cycle_length=2, block_length=4)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 1, 1, 1,\n",
      "     2, 2, 2, 2,\n",
      "     1, 1,\n",
      "     2, 2,\n",
      "     3, 3, 3, 3,\n",
      "     4, 4, 4, 4,\n",
      "     3, 3,\n",
      "     4, 4,\n",
      "     5, 5, 5, 5,\n",
      "     5, 5]\n",
      "\n",
      "    Note: The order of elements yielded by this transformation is\n",
      "    deterministic, as long as `map_func` is a pure function and\n",
      "    `deterministic=True`. If `map_func` contains any stateful operations, the\n",
      "    order in which that state is accessed is undefined.\n",
      "\n",
      "    Performance can often be improved by setting `num_parallel_calls` so that\n",
      "    `interleave` will use multiple threads to fetch elements. If determinism\n",
      "    isn't required, it can also improve performance to set\n",
      "    `deterministic=False`.\n",
      "\n",
      "    >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      "    ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      "    >>> dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x),\n",
      "    ...     cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
      "    ...     deterministic=False)\n",
      "\n",
      "    Args:\n",
      "      map_func: A function that takes a dataset element and returns a\n",
      "        `tf.data.Dataset`.\n",
      "      cycle_length: (Optional.) The number of input elements that will be\n",
      "        processed concurrently. If not set, the tf.data runtime decides what it\n",
      "        should be based on available CPU. If `num_parallel_calls` is set to\n",
      "        `tf.data.AUTOTUNE`, the `cycle_length` argument identifies\n",
      "        the maximum degree of parallelism.\n",
      "      block_length: (Optional.) The number of consecutive elements to produce\n",
      "        from each input element before cycling to another input element. If not\n",
      "        set, defaults to 1.\n",
      "      num_parallel_calls: (Optional.) If specified, the implementation creates a\n",
      "        threadpool, which is used to fetch inputs from cycle elements\n",
      "        asynchronously and in parallel. The default behavior is to fetch inputs\n",
      "        from cycle elements synchronously with no parallelism. If the value\n",
      "        `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      "        calls is set dynamically based on available CPU.\n",
      "      deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      "        boolean is specified (`True` or `False`), it controls the order in which\n",
      "        the transformation produces elements. If set to `False`, the\n",
      "        transformation is allowed to yield elements out of order to trade\n",
      "        determinism for performance. If not specified, the\n",
      "        `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      "        behavior.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mblock_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mblock_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mcycle_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mcycle_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The `deterministic` argument has no effect unless the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34m\"`num_parallel_calls` argument is specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mInterleaveDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mParallelInterleaveDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mcycle_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mblock_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Filters this dataset according to `predicate`.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> dataset = dataset.filter(lambda x: x < 3)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 2]\n",
      "    >>> # `tf.math.equal(x, y)` is required for equality comparison\n",
      "    >>> def filter_fn(x):\n",
      "    ...   return tf.math.equal(x, 1)\n",
      "    >>> dataset = dataset.filter(filter_fn)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1]\n",
      "\n",
      "    Args:\n",
      "      predicate: A function mapping a dataset element to a boolean.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: The `Dataset` containing the elements of this dataset for which\n",
      "          `predicate` is `True`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mFilterDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Applies a transformation function to this dataset.\n",
      "\n",
      "    `apply` enables chaining of custom `Dataset` transformations, which are\n",
      "    represented as functions that take one `Dataset` argument and return a\n",
      "    transformed `Dataset`.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(100)\n",
      "    >>> def dataset_fn(ds):\n",
      "    ...   return ds.filter(lambda x: x < 5)\n",
      "    >>> dataset = dataset.apply(dataset_fn)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [0, 1, 2, 3, 4]\n",
      "\n",
      "    Args:\n",
      "      transformation_func: A function that takes one `Dataset` argument and\n",
      "        returns a `Dataset`.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: The `Dataset` returned by applying `transformation_func` to this\n",
      "          dataset.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34mf\"`transformation_func` must return a `tf.data.Dataset` object. \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34mf\"Got {type(dataset)}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_datasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns a dataset of \"windows\".\n",
      "\n",
      "    Each \"window\" is a dataset that contains a subset of elements of the\n",
      "    input dataset. These are finite datasets of size `size` (or possibly fewer\n",
      "    if there are not enough input elements to fill the window and\n",
      "    `drop_remainder` evaluates to `False`).\n",
      "\n",
      "    For example:\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(7).window(3)\n",
      "    >>> for window in dataset:\n",
      "    ...   print(window)\n",
      "    <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "    <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "    <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "\n",
      "    Since windows are datasets, they can be iterated over:\n",
      "\n",
      "    >>> for window in dataset:\n",
      "    ...   print([item.numpy() for item in window])\n",
      "    [0, 1, 2]\n",
      "    [3, 4, 5]\n",
      "    [6]\n",
      "\n",
      "    #### Shift\n",
      "\n",
      "    The `shift` argument determines the number of input elements to shift\n",
      "    between the start of each window. If windows and elements are both numbered\n",
      "    starting at 0, the first element in window `k` will be element `k * shift`\n",
      "    of the input dataset. In particular, the first element of the first window\n",
      "    will always be the first element of the input dataset.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
      "    ...                                           drop_remainder=True)\n",
      "    >>> for window in dataset:\n",
      "    ...   print(list(window.as_numpy_iterator()))\n",
      "    [0, 1, 2]\n",
      "    [1, 2, 3]\n",
      "    [2, 3, 4]\n",
      "    [3, 4, 5]\n",
      "    [4, 5, 6]\n",
      "\n",
      "    #### Stride\n",
      "\n",
      "    The `stride` argument determines the stride between input elements within a\n",
      "    window.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(7).window(3, shift=1, stride=2,\n",
      "    ...                                           drop_remainder=True)\n",
      "    >>> for window in dataset:\n",
      "    ...   print(list(window.as_numpy_iterator()))\n",
      "    [0, 2, 4]\n",
      "    [1, 3, 5]\n",
      "    [2, 4, 6]\n",
      "\n",
      "    #### Nested elements\n",
      "\n",
      "    When the `window` transformation is applied to a dataset whos elements are\n",
      "    nested structures, it produces a dataset where the elements have the same\n",
      "    nested structure but each leaf is replaced by a window. In other words,\n",
      "    the nesting is applied outside of the windows as opposed inside of them.\n",
      "\n",
      "    The type signature is:\n",
      "\n",
      "    ```\n",
      "    def window(\n",
      "        self: Dataset[Nest[T]], ...\n",
      "    ) -> Dataset[Nest[Dataset[T]]]\n",
      "    ```\n",
      "\n",
      "    Applying `window` to a `Dataset` of tuples gives a tuple of windows:\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
      "    ...                                               [6, 7, 8, 9, 10]))\n",
      "    >>> dataset = dataset.window(2)\n",
      "    >>> windows = next(iter(dataset))\n",
      "    >>> windows\n",
      "    (<...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>,\n",
      "     <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>)\n",
      "\n",
      "    >>> def to_numpy(ds):\n",
      "    ...   return list(ds.as_numpy_iterator())\n",
      "    >>>\n",
      "    >>> for windows in dataset:\n",
      "    ...   print(to_numpy(windows[0]), to_numpy(windows[1]))\n",
      "    [1, 2] [6, 7]\n",
      "    [3, 4] [8, 9]\n",
      "    [5] [10]\n",
      "\n",
      "    Applying `window` to a `Dataset` of dictionaries gives a dictionary of\n",
      "    `Datasets`:\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices({'a': [1, 2, 3],\n",
      "    ...                                               'b': [4, 5, 6],\n",
      "    ...                                               'c': [7, 8, 9]})\n",
      "    >>> dataset = dataset.window(2)\n",
      "    >>> def to_numpy(ds):\n",
      "    ...   return list(ds.as_numpy_iterator())\n",
      "    >>>\n",
      "    >>> for windows in dataset:\n",
      "    ...   print(tf.nest.map_structure(to_numpy, windows))\n",
      "    {'a': [1, 2], 'b': [4, 5], 'c': [7, 8]}\n",
      "    {'a': [3], 'b': [6], 'c': [9]}\n",
      "\n",
      "    #### Flatten a dataset of windows\n",
      "\n",
      "    The `Dataset.flat_map` and `Dataset.interleave` methods can be used to\n",
      "    flatten a dataset of windows into a single dataset.\n",
      "\n",
      "    The argument to `flat_map` is a function that takes an element from the\n",
      "    dataset and returns a `Dataset`. `flat_map` chains together the resulting\n",
      "    datasets sequentially.\n",
      "\n",
      "    For example, to turn each window into a dense tensor:\n",
      "\n",
      "    >>> size = 3\n",
      "    >>> dataset = tf.data.Dataset.range(7).window(size, shift=1,\n",
      "    ...                                           drop_remainder=True)\n",
      "    >>> batched = dataset.flat_map(lambda x:x.batch(3))\n",
      "    >>> for batch in batched:\n",
      "    ...   print(batch.numpy())\n",
      "    [0 1 2]\n",
      "    [1 2 3]\n",
      "    [2 3 4]\n",
      "    [3 4 5]\n",
      "    [4 5 6]\n",
      "\n",
      "    Args:\n",
      "      size: A `tf.int64` scalar `tf.Tensor`, representing the number of elements\n",
      "        of the input dataset to combine into a window. Must be positive.\n",
      "      shift: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      "        number of input elements by which the window moves in each iteration.\n",
      "        Defaults to `size`. Must be positive.\n",
      "      stride: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      "        stride of the input elements in the sliding window. Must be positive.\n",
      "        The default value of 1 means \"retain every input element\".\n",
      "      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      "        whether the last windows should be dropped if their size is smaller than\n",
      "        `size`.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset` of (nests of) windows. Each window is a finite\n",
      "        datasets of flat elements.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mshift\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mshift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mWindowDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Reduces the input dataset to a single element.\n",
      "\n",
      "    The transformation calls `reduce_func` successively on every element of\n",
      "    the input dataset until the dataset is exhausted, aggregating information in\n",
      "    its internal state. The `initial_state` argument is used for the initial\n",
      "    state and the final state is returned as the result.\n",
      "\n",
      "    >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
      "    5\n",
      "    >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()\n",
      "    10\n",
      "\n",
      "    Args:\n",
      "      initial_state: An element representing the initial state of the\n",
      "        transformation.\n",
      "      reduce_func: A function that maps `(old_state, input_element)` to\n",
      "        `new_state`. It must take two arguments and return a new element\n",
      "        The structure of `new_state` must match the structure of\n",
      "        `initial_state`.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A dataset element corresponding to the final state of the transformation.\n",
      "\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial_state\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstate_structure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Iteratively rerun the reduce function until reaching a fixed point on\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# `state_structure`.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mneed_to_rerun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mwhile\u001b[0m \u001b[0mneed_to_rerun\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mwrapped_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStructuredFunctionWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34m\"reduce()\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0minput_structure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0madd_to_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# Extract and validate class information from the returned values.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moutput_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mstate_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mlambda\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_legacy_output_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mstate_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mnew_state_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_class\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_state_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;34mf\"The element classes for the new state must match the initial \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;34mf\"state. Expected {state_classes} but got \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;34mf\"{wrapped_func.output_classes}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# Extract and validate type information from the returned values.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moutput_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mstate_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mlambda\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_legacy_output_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mstate_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mnew_state_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mnew_state_type\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstate_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;34mf\"The element types for the new state must match the initial \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;34mf\"state. Expected {state_types} but got \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;34mf\"{wrapped_func.output_types}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# Extract shape information from the returned values.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0moutput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mstate_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mlambda\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_legacy_output_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mstate_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mflat_state_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mflat_new_state_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mweakened_state_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0moriginal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mfor\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_state_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_new_state_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mneed_to_rerun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0moriginal_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweakened_shape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_state_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                \u001b[0mweakened_state_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moriginal_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mweakened_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0moriginal_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mweakened_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mneed_to_rerun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mbreak\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mneed_to_rerun\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# TODO(b/110122868): Support a \"most specific compatible structure\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# method for combining structures, to avoid using legacy structures\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# here.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstate_structure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_legacy_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mstate_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweakened_state_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mstate_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mreduce_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mreduce_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_debug_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_and_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mstate_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mreduce_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0moutput_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_flat_tensor_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mget_single_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns the single element of the `dataset`.\n",
      "\n",
      "    The function enables you to use a `tf.data.Dataset` in a stateless\n",
      "    \"tensor-in tensor-out\" expression, without creating an iterator.\n",
      "    This facilitates the ease of data transformation on tensors using the\n",
      "    optimized `tf.data.Dataset` abstraction on top of them.\n",
      "\n",
      "    For example, lets consider a `preprocessing_fn` which would take as an\n",
      "    input the raw features and returns the processed feature along with\n",
      "    it's label.\n",
      "\n",
      "    ```python\n",
      "    def preprocessing_fn(raw_feature):\n",
      "      # ... the raw_feature is preprocessed as per the use-case\n",
      "      return feature\n",
      "\n",
      "    raw_features = ...  # input batch of BATCH_SIZE elements.\n",
      "    dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
      "              .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      "              .batch(BATCH_SIZE))\n",
      "\n",
      "    processed_features = dataset.get_single_element()\n",
      "    ```\n",
      "\n",
      "    In the above example, the `raw_features` tensor of length=BATCH_SIZE\n",
      "    was converted to a `tf.data.Dataset`. Next, each of the `raw_feature` was\n",
      "    mapped using the `preprocessing_fn` and the processed features were\n",
      "    grouped into a single batch. The final `dataset` contains only one element\n",
      "    which is a batch of all the processed features.\n",
      "\n",
      "    NOTE: The `dataset` should contain only one element.\n",
      "\n",
      "    Now, instead of creating an iterator for the `dataset` and retrieving the\n",
      "    batch of features, the `tf.data.get_single_element()` function is used\n",
      "    to skip the iterator creation process and directly output the batch of\n",
      "    features.\n",
      "\n",
      "    This can be particularly useful when your tensor transformations are\n",
      "    expressed as `tf.data.Dataset` operations, and you want to use those\n",
      "    transformations while serving your model.\n",
      "\n",
      "    #### Keras\n",
      "\n",
      "    ```python\n",
      "\n",
      "    model = ... # A pre-built or custom model\n",
      "\n",
      "    class PreprocessingModel(tf.keras.Model):\n",
      "      def __init__(self, model):\n",
      "        super().__init__(self)\n",
      "        self.model = model\n",
      "\n",
      "      @tf.function(input_signature=[...])\n",
      "      def serving_fn(self, data):\n",
      "        ds = tf.data.Dataset.from_tensor_slices(data)\n",
      "        ds = ds.map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      "        ds = ds.batch(batch_size=BATCH_SIZE)\n",
      "        return tf.argmax(self.model(ds.get_single_element()), axis=-1)\n",
      "\n",
      "    preprocessing_model = PreprocessingModel(model)\n",
      "    your_exported_model_dir = ... # save the model to this path.\n",
      "    tf.saved_model.save(preprocessing_model, your_exported_model_dir,\n",
      "                  signatures={'serving_default': preprocessing_model.serving_fn}\n",
      "                  )\n",
      "    ```\n",
      "\n",
      "    #### Estimator\n",
      "\n",
      "    In the case of estimators, you need to generally define a `serving_input_fn`\n",
      "    which would require the features to be processed by the model while\n",
      "    inferencing.\n",
      "\n",
      "    ```python\n",
      "    def serving_input_fn():\n",
      "\n",
      "      raw_feature_spec = ... # Spec for the raw_features\n",
      "      input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
      "          raw_feature_spec, default_batch_size=None)\n",
      "      )\n",
      "      serving_input_receiver = input_fn()\n",
      "      raw_features = serving_input_receiver.features\n",
      "\n",
      "      def preprocessing_fn(raw_feature):\n",
      "        # ... the raw_feature is preprocessed as per the use-case\n",
      "        return feature\n",
      "\n",
      "      dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
      "                .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      "                .batch(BATCH_SIZE))\n",
      "\n",
      "      processed_features = dataset.get_single_element()\n",
      "\n",
      "      # Please note that the value of `BATCH_SIZE` should be equal to\n",
      "      # the size of the leading dimension of `raw_features`. This ensures\n",
      "      # that `dataset` has only element, which is a pre-requisite for\n",
      "      # using `dataset.get_single_element()`.\n",
      "\n",
      "      return tf.estimator.export.ServingInputReceiver(\n",
      "          processed_features, serving_input_receiver.receiver_tensors)\n",
      "\n",
      "    estimator = ... # A pre-built or custom estimator\n",
      "    estimator.export_saved_model(your_exported_model_dir, serving_input_fn)\n",
      "    ```\n",
      "\n",
      "    Args:\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A nested structure of `tf.Tensor` objects, corresponding to the single\n",
      "      element of `dataset`.\n",
      "\n",
      "    Raises:\n",
      "      InvalidArgumentError: (at runtime) if `dataset` does not contain exactly\n",
      "        one element.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_and_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_to_single_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0munbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Splits elements of a dataset into multiple elements.\n",
      "\n",
      "    For example, if elements of the dataset are shaped `[B, a0, a1, ...]`,\n",
      "    where `B` may vary for each input element, then for each element in the\n",
      "    dataset, the unbatched dataset will contain `B` consecutive elements\n",
      "    of shape `[a0, a1, ...]`.\n",
      "\n",
      "    >>> elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
      "    >>> dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
      "    >>> dataset = dataset.unbatch()\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 2, 3, 1, 2, 1, 2, 3, 4]\n",
      "\n",
      "    Note: `unbatch` requires a data copy to slice up the batched tensor into\n",
      "    smaller, unbatched tensors. When optimizing performance, try to avoid\n",
      "    unnecessary usage of `unbatch`.\n",
      "\n",
      "    Args:\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnormalized_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_to_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_UnbatchDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mwith_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns a new `tf.data.Dataset` with the given options set.\n",
      "\n",
      "    The options are \"global\" in the sense they apply to the entire dataset.\n",
      "    If options are set multiple times, they are merged as long as different\n",
      "    options do not use different non-default values.\n",
      "\n",
      "    >>> ds = tf.data.Dataset.range(5)\n",
      "    >>> ds = ds.interleave(lambda x: tf.data.Dataset.range(5),\n",
      "    ...                    cycle_length=3,\n",
      "    ...                    num_parallel_calls=3)\n",
      "    >>> options = tf.data.Options()\n",
      "    >>> # This will make the interleave order non-deterministic.\n",
      "    >>> options.deterministic = False\n",
      "    >>> ds = ds.with_options(options)\n",
      "\n",
      "    Args:\n",
      "      options: A `tf.data.Options` that identifies the options the use.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset` with the given options.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: when an option is set more than once to a non-default value\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_OptionsDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Returns the cardinality of the dataset, if known.\n",
      "\n",
      "    `cardinality` may return `tf.data.INFINITE_CARDINALITY` if the dataset\n",
      "    contains an infinite number of elements or `tf.data.UNKNOWN_CARDINALITY` if\n",
      "    the analysis fails to determine the number of elements in the dataset\n",
      "    (e.g. when the dataset source is a file).\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(42)\n",
      "    >>> print(dataset.cardinality().numpy())\n",
      "    42\n",
      "    >>> dataset = dataset.repeat()\n",
      "    >>> cardinality = dataset.cardinality()\n",
      "    >>> print((cardinality == tf.data.INFINITE_CARDINALITY).numpy())\n",
      "    True\n",
      "    >>> dataset = dataset.filter(lambda x: True)\n",
      "    >>> cardinality = dataset.cardinality()\n",
      "    >>> print((cardinality == tf.data.UNKNOWN_CARDINALITY).numpy())\n",
      "    True\n",
      "\n",
      "    Returns:\n",
      "      A scalar `tf.int64` `Tensor` representing the cardinality of the dataset.\n",
      "      If the cardinality is infinite or unknown, `cardinality` returns the\n",
      "      named constants `tf.data.INFINITE_CARDINALITY` and\n",
      "      `tf.data.UNKNOWN_CARDINALITY` respectively.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mgroup_by_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[0mkey_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[0mwindow_size_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Groups windows of elements by key and reduces them.\n",
      "\n",
      "    This transformation maps each consecutive element in a dataset to a key\n",
      "    using `key_func` and groups the elements by key. It then applies\n",
      "    `reduce_func` to at most `window_size_func(key)` elements matching the same\n",
      "    key. All except the final window for each key will contain\n",
      "    `window_size_func(key)` elements; the final window may be smaller.\n",
      "\n",
      "    You may provide either a constant `window_size` or a window size determined\n",
      "    by the key through `window_size_func`.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(10)\n",
      "    >>> window_size = 5\n",
      "    >>> key_func = lambda x: x%2\n",
      "    >>> reduce_func = lambda key, dataset: dataset.batch(window_size)\n",
      "    >>> dataset = dataset.group_by_window(\n",
      "    ...           key_func=key_func,\n",
      "    ...           reduce_func=reduce_func,\n",
      "    ...           window_size=window_size)\n",
      "    >>> for elem in dataset.as_numpy_iterator():\n",
      "    ...   print(elem)\n",
      "    [0 2 4 6 8]\n",
      "    [1 3 5 7 9]\n",
      "\n",
      "    Args:\n",
      "      key_func: A function mapping a nested structure of tensors (having shapes\n",
      "        and types defined by `self.output_shapes` and `self.output_types`) to a\n",
      "        scalar `tf.int64` tensor.\n",
      "      reduce_func: A function mapping a key and a dataset of up to `window_size`\n",
      "        consecutive elements matching that key to another dataset.\n",
      "      window_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      "        consecutive elements matching the same key to combine in a single batch,\n",
      "        which will be passed to `reduce_func`. Mutually exclusive with\n",
      "        `window_size_func`.\n",
      "      window_size_func: A function mapping a key to a `tf.int64` scalar\n",
      "        `tf.Tensor`, representing the number of consecutive elements matching\n",
      "        the same key to combine in a single batch, which will be passed to\n",
      "        `reduce_func`. Mutually exclusive with `window_size`.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A `Dataset`.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: if neither or both of {`window_size`, `window_size_func`} are\n",
      "        passed.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mwindow_size_func\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mwindow_size_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Either the `window_size` argument or the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                       \u001b[1;34m\"`window_size_func` argument must be specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mdef\u001b[0m \u001b[0mconstant_window_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munused_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mwindow_size_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant_window_func\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32massert\u001b[0m \u001b[0mwindow_size_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_GroupByWindowDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mbucket_by_sequence_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0melement_length_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0mbucket_boundaries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0mbucket_batch_sizes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0mpadded_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0mpadding_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0mpad_to_bucket_boundary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0mno_padding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"A transformation that buckets elements in a `Dataset` by length.\n",
      "\n",
      "    Elements of the `Dataset` are grouped together by length and then are padded\n",
      "    and batched.\n",
      "\n",
      "    This is useful for sequence tasks in which the elements have variable\n",
      "    length. Grouping together elements that have similar lengths reduces the\n",
      "    total fraction of padding in a batch which increases training step\n",
      "    efficiency.\n",
      "\n",
      "    Below is an example to bucketize the input data to the 3 buckets\n",
      "    \"[0, 3), [3, 5), [5, inf)\" based on sequence length, with batch size 2.\n",
      "\n",
      "    >>> elements = [\n",
      "    ...   [0], [1, 2, 3, 4], [5, 6, 7],\n",
      "    ...   [7, 8, 9, 10, 11], [13, 14, 15, 16, 19, 20], [21, 22]]\n",
      "    >>> dataset = tf.data.Dataset.from_generator(\n",
      "    ...     lambda: elements, tf.int64, output_shapes=[None])\n",
      "    >>> dataset = dataset.bucket_by_sequence_length(\n",
      "    ...         element_length_func=lambda elem: tf.shape(elem)[0],\n",
      "    ...         bucket_boundaries=[3, 5],\n",
      "    ...         bucket_batch_sizes=[2, 2, 2])\n",
      "    >>> for elem in dataset.as_numpy_iterator():\n",
      "    ...   print(elem)\n",
      "    [[1 2 3 4]\n",
      "    [5 6 7 0]]\n",
      "    [[ 7  8  9 10 11  0]\n",
      "    [13 14 15 16 19 20]]\n",
      "    [[ 0  0]\n",
      "    [21 22]]\n",
      "\n",
      "    Args:\n",
      "      element_length_func: function from element in `Dataset` to `tf.int32`,\n",
      "        determines the length of the element, which will determine the bucket it\n",
      "        goes into.\n",
      "      bucket_boundaries: `list<int>`, upper length boundaries of the buckets.\n",
      "      bucket_batch_sizes: `list<int>`, batch size per bucket. Length should be\n",
      "        `len(bucket_boundaries) + 1`.\n",
      "      padded_shapes: Nested structure of `tf.TensorShape` to pass to\n",
      "        `tf.data.Dataset.padded_batch`. If not provided, will use\n",
      "        `dataset.output_shapes`, which will result in variable length dimensions\n",
      "        being padded out to the maximum length in each batch.\n",
      "      padding_values: Values to pad with, passed to\n",
      "        `tf.data.Dataset.padded_batch`. Defaults to padding with 0.\n",
      "      pad_to_bucket_boundary: bool, if `False`, will pad dimensions with unknown\n",
      "        size to maximum length in batch. If `True`, will pad dimensions with\n",
      "        unknown size to bucket boundary minus 1 (i.e., the maximum length in\n",
      "        each bucket), and caller must ensure that the source `Dataset` does not\n",
      "        contain any elements with length longer than `max(bucket_boundaries)`.\n",
      "      no_padding: `bool`, indicates whether to pad the batch features (features\n",
      "        need to be either of type `tf.sparse.SparseTensor` or of same shape).\n",
      "      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      "        whether the last batch should be dropped in the case it has fewer than\n",
      "        `batch_size` elements; the default behavior is not to drop the smaller\n",
      "        batch.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A `Dataset`.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: if `len(bucket_batch_sizes) != len(bucket_boundaries) + 1`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_batch_sizes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_boundaries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34mf\"`len(bucket_batch_sizes)` must equal `len(bucket_boundaries) + 1` \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34mf\"but `len(bucket_batch_sizes)={len(bucket_batch_sizes)}` and \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;34mf\"`len(bucket_boundaries)={len(bucket_boundaries)}`.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_batch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0melement_to_bucket_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;34m\"\"\"Return int64 id of the length bucket for this element.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mseq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melement_length_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mboundaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mbuckets_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mbuckets_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboundaries\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mconditions_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mless_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuckets_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mless\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuckets_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mbucket_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_min\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mbucket_id\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mwindow_size_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# The window size is set to the batch size for this bucket\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mwindow_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mmake_padded_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnone_filler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mpadded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mnone_filler\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpadded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mbatching_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrouped_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;34m\"\"\"Batch elements in dataset.\"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindow_size_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mno_padding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mgrouped_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_remainder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mnone_filler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mpad_to_bucket_boundary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"When pad_to_bucket_boundary=True, elements must have \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                   \u001b[1;34m\"length < max(bucket_boundaries).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_less\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mbucket_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_batch_sizes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mboundaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0mbucket_boundaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mbucket_boundary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mnone_filler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbucket_boundary\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_legacy_output_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrouped_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_padded_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mpadded_shapes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnone_filler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnone_filler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mgrouped_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mshapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mpadding_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mdrop_remainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_remainder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_by_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mkey_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melement_to_bucket_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatching_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mwindow_size_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow_size_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a `Dataset` of pseudorandom values.\n",
      "\n",
      "    The dataset generates a sequence of uniformly distributed integer values.\n",
      "\n",
      "    >>> ds1 = tf.data.Dataset.random(seed=4).take(10)\n",
      "    >>> ds2 = tf.data.Dataset.random(seed=4).take(10)\n",
      "    >>> print(list(ds2.as_numpy_iterator())==list(ds2.as_numpy_iterator()))\n",
      "    True\n",
      "\n",
      "    Args:\n",
      "      seed: (Optional) If specified, the dataset produces a deterministic\n",
      "        sequence of values.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mRandomDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0msnapshot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"AUTO\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mreader_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mshard_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m               \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"API to persist the output of the input dataset.\n",
      "\n",
      "    The snapshot API allows users to transparently persist the output of their\n",
      "    preprocessing pipeline to disk, and materialize the pre-processed data on a\n",
      "    different training run.\n",
      "\n",
      "    This API enables repeated preprocessing steps to be consolidated, and allows\n",
      "    re-use of already processed data, trading off disk storage and network\n",
      "    bandwidth for freeing up more valuable CPU resources and accelerator compute\n",
      "    time.\n",
      "\n",
      "    https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md\n",
      "    has detailed design documentation of this feature.\n",
      "\n",
      "    Users can specify various options to control the behavior of snapshot,\n",
      "    including how snapshots are read from and written to by passing in\n",
      "    user-defined functions to the `reader_func` and `shard_func` parameters.\n",
      "\n",
      "    `shard_func` is a user specified function that maps input elements to\n",
      "    snapshot shards.\n",
      "\n",
      "    Users may want to specify this function to control how snapshot files should\n",
      "    be written to disk. Below is an example of how a potential `shard_func`\n",
      "    could be written.\n",
      "\n",
      "    ```python\n",
      "    dataset = ...\n",
      "    dataset = dataset.enumerate()\n",
      "    dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\n",
      "        shard_func=lambda x, y: x % NUM_SHARDS, ...)\n",
      "    dataset = dataset.map(lambda x, y: y)\n",
      "    ```\n",
      "\n",
      "    `reader_func` is a user specified function that accepts a single argument:\n",
      "    (1) a Dataset of Datasets, each representing a \"split\" of elements of the\n",
      "    original dataset. The cardinality of the input dataset matches the\n",
      "    number of the shards specified in the `shard_func` (see above). The function\n",
      "    should return a Dataset of elements of the original dataset.\n",
      "\n",
      "    Users may want specify this function to control how snapshot files should be\n",
      "    read from disk, including the amount of shuffling and parallelism.\n",
      "\n",
      "    Here is an example of a standard reader function a user can define. This\n",
      "    function enables both dataset shuffling and parallel reading of datasets:\n",
      "\n",
      "    ```python\n",
      "    def user_reader_func(datasets):\n",
      "      # shuffle the datasets splits\n",
      "      datasets = datasets.shuffle(NUM_CORES)\n",
      "      # read datasets in parallel and interleave their elements\n",
      "      return datasets.interleave(lambda x: x, num_parallel_calls=AUTOTUNE)\n",
      "\n",
      "    dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\n",
      "        reader_func=user_reader_func)\n",
      "    ```\n",
      "\n",
      "    By default, snapshot parallelizes reads by the number of cores available on\n",
      "    the system, but will not attempt to shuffle the data.\n",
      "\n",
      "    Args:\n",
      "      path: Required. A directory to use for storing / loading the snapshot to /\n",
      "        from.\n",
      "      compression: Optional. The type of compression to apply to the snapshot\n",
      "        written to disk. Supported options are `GZIP`, `SNAPPY`, `AUTO` or None.\n",
      "        Defaults to `AUTO`, which attempts to pick an appropriate compression\n",
      "        algorithm for the dataset.\n",
      "      reader_func: Optional. A function to control how to read data from\n",
      "        snapshot shards.\n",
      "      shard_func: Optional. A function to control how to shard data when writing\n",
      "        a snapshot.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mproject_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minput_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mshard_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0minput_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# This sets the amount of parallelism based on the number of CPU cores on\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# the machine where this Python code is executed, which may differ from\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# the number of CPU cores where the input pipeline graph is actually\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# executed (e.g. remote Cloud TPU workers).\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mlocal_shard_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mproject_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mlocal_shard_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshard_func\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_SnapshotDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0minput_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mreader_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreader_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# This will not do the right thing where the graph is built on a\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# different machine than the executor (e.g. Cloud TPUs).\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mshard_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_shard_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mproject_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mscan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscan_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"A transformation that scans a function across an input dataset.\n",
      "\n",
      "    This transformation is a stateful relative of `tf.data.Dataset.map`.\n",
      "    In addition to mapping `scan_func` across the elements of the input dataset,\n",
      "    `scan()` accumulates one or more state tensors, whose initial values are\n",
      "    `initial_state`.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(10)\n",
      "    >>> initial_state = tf.constant(0, dtype=tf.int64)\n",
      "    >>> scan_func = lambda state, i: (state + i, state + i)\n",
      "    >>> dataset = dataset.scan(initial_state=initial_state, scan_func=scan_func)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]\n",
      "\n",
      "    Args:\n",
      "      initial_state: A nested structure of tensors, representing the initial\n",
      "        state of the accumulator.\n",
      "      scan_func: A function that maps `(old_state, input_element)` to\n",
      "        `(new_state, output_element)`. It must take two arguments and return a\n",
      "        pair of nested structures of tensors. The `new_state` must match the\n",
      "        structure of `initial_state`.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_ScanDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscan_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscan_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mtake_while\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"A transformation that stops dataset iteration based on a `predicate`.\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.range(10)\n",
      "    >>> dataset = dataset.take_while(lambda x: x < 5)\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [0, 1, 2, 3, 4]\n",
      "\n",
      "    Args:\n",
      "      predicate: A function that maps a nested structure of tensors (having\n",
      "        shapes and types defined by `self.output_shapes` and\n",
      "        `self.output_types`) to a scalar `tf.bool` tensor.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_TakeWhileDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"A transformation that discards duplicate elements of a `Dataset`.\n",
      "\n",
      "    Use this transformation to produce a dataset that contains one instance of\n",
      "    each unique element in the input. For example:\n",
      "\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\n",
      "    >>> dataset = dataset.unique()\n",
      "    >>> sorted(list(dataset.as_numpy_iterator()))\n",
      "    [1, 2, 37]\n",
      "\n",
      "    Note: This transformation only supports datasets which fit into memory\n",
      "    and have elements of either `tf.int32`, `tf.int64` or `tf.string` type.\n",
      "\n",
      "    Args:\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A `Dataset`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_UniqueDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mrejection_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                         \u001b[0mclass_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                         \u001b[0mtarget_dist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                         \u001b[0minitial_dist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                         \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"A transformation that resamples a dataset to a target distribution.\n",
      "\n",
      "    Lets consider the following example where a dataset with an initial data\n",
      "    distribution of `init_dist` needs to be resampled into a dataset with\n",
      "    `target_dist` distribution.\n",
      "\n",
      "    >>> initial_dist = [0.6, 0.4]\n",
      "    >>> num_classes = len(initial_dist)\n",
      "    >>> num_samples = 1000\n",
      "    >>> data_np = np.random.choice(num_classes, num_samples, p=initial_dist)\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(data_np)\n",
      "\n",
      "    The value of `x` will be close to `{0: 50000, 1: 50000}` as per the\n",
      "    `initial_dist` distribution.\n",
      "\n",
      "    >>> target_dist = [0.5, 0.5]\n",
      "    >>> resampled_dataset = dataset.rejection_resample(\n",
      "    ...    class_func=lambda x: x,\n",
      "    ...    target_dist=target_dist,\n",
      "    ...    initial_dist=initial_dist)\n",
      "    >>> resampled_dataset = resampled_dataset.map(\n",
      "    ...     lambda class_func_result, data: data)\n",
      "\n",
      "\n",
      "    The value distribution of classes in the resampled_distribution will be now\n",
      "    be close to the target distribution.\n",
      "\n",
      "    Args:\n",
      "      class_func: A function mapping an element of the input dataset to a scalar\n",
      "        `tf.int32` tensor. Values should be in `[0, num_classes)`.\n",
      "      target_dist: A floating point type tensor, shaped `[num_classes]`.\n",
      "      initial_dist: (Optional.)  A floating point type tensor, shaped\n",
      "        `[num_classes]`.  If not provided, the true class distribution is\n",
      "        estimated live in a streaming fashion.\n",
      "      seed: (Optional.) Python integer seed for the resampler.\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "\n",
      "    Returns:\n",
      "      A `Dataset`\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtarget_dist_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"target_dist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtarget_dist_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_dist_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Get initial distribution.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0minitial_dist\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0minitial_dist_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"initial_dist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0minitial_dist_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_dist_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0macceptance_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_of_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0m_calculate_acceptance_probs_with_mixing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_dist_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                                  \u001b[0mtarget_dist_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0minitial_dist_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0minitial_dist_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0macceptance_dist_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0macceptance_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mprob_of_original_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mprob_of_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0minitial_dist_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_estimate_initial_dist_ds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mtarget_dist_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0macceptance_and_original_prob_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_dist_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mlambda\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_calculate_acceptance_probs_with_mixing\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# pylint: disable=g-long-lambda\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_dist_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0macceptance_dist_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macceptance_and_original_prob_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mlambda\u001b[0m \u001b[0maccept_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maccept_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mprob_of_original_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macceptance_and_original_prob_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_original\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprob_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfiltered_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_filter_ds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macceptance_dist_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_dist_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                             \u001b[0mclass_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Prefetch filtered dataset for speed.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfiltered_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprob_original_static\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_prob_original_static\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0minitial_dist_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_dist_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minitial_dist\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0madd_class_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mclass_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mclass_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mprob_original_static\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_class_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melif\u001b[0m \u001b[0mprob_original_static\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mfiltered_ds\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_from_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_class_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_ds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprob_of_original_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0msample_from_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                           \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                           \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                           \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Samples elements at random from the datasets in `datasets`.\n",
      "\n",
      "    Creates a dataset by interleaving elements of `datasets` with `weight[i]`\n",
      "    probability of picking an element from dataset `i`. Sampling is done without\n",
      "    replacement. For example, suppose we have 2 datasets:\n",
      "\n",
      "    ```python\n",
      "    dataset1 = tf.data.Dataset.range(0, 3)\n",
      "    dataset2 = tf.data.Dataset.range(100, 103)\n",
      "    ```\n",
      "\n",
      "    Suppose that we sample from these 2 datasets with the following weights:\n",
      "\n",
      "    ```python\n",
      "    sample_dataset = tf.data.Dataset.sample_from_datasets(\n",
      "        [dataset1, dataset2], weights=[0.5, 0.5])\n",
      "    ```\n",
      "\n",
      "    One possible outcome of elements in sample_dataset is:\n",
      "\n",
      "    ```\n",
      "    print(list(sample_dataset.as_numpy_iterator()))\n",
      "    # [100, 0, 1, 101, 2, 102]\n",
      "    ```\n",
      "\n",
      "    Args:\n",
      "      datasets: A non-empty list of `tf.data.Dataset` objects with compatible\n",
      "        structure.\n",
      "      weights: (Optional.) A list or Tensor of `len(datasets)` floating-point\n",
      "        values where `weights[i]` represents the probability to sample from\n",
      "        `datasets[i]`, or a `tf.data.Dataset` object where each element is such\n",
      "        a list. Defaults to a uniform distribution across `datasets`.\n",
      "      seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      "        seed that will be used to create the distribution. See\n",
      "        `tf.random.set_seed` for behavior.\n",
      "      stop_on_empty_dataset: If `True`, sampling stops if it encounters an empty\n",
      "        dataset. If `False`, it continues sampling and skips any empty datasets.\n",
      "        It is recommended to set it to `True`. Otherwise, the distribution of\n",
      "        samples starts off as the user intends, but may change as input datasets\n",
      "        become empty. This can be difficult to detect since the dataset starts\n",
      "        off looking correct. Default to `False` for backward compatibility.\n",
      "\n",
      "    Returns:\n",
      "      A dataset that interleaves elements from `datasets` at random, according\n",
      "      to `weights` if provided, otherwise with uniform probability.\n",
      "\n",
      "    Raises:\n",
      "      TypeError: If the `datasets` or `weights` arguments have the wrong type.\n",
      "      ValueError:\n",
      "        - If `datasets` is empty, or\n",
      "        - If `weights` is specified and does not match the length of `datasets`.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_skip_datasets_with_zero_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mdatasets_and_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                              \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                              \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdatasets_and_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdatasets_and_weights\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m\n",
      "\u001b[0m              \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid `datasets`. `datasets` should not be empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Select inputs with uniform probability.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid `weights`. The shape of `weights` \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                             \u001b[1;34mf\"should be compatible with `[len(datasets)]` \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                             \u001b[1;34mf\"but is {weights.shape}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid `weights`. `weights` should have the \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                             \u001b[1;34mf\"same length as `datasets` but got \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                             \u001b[1;34mf\"`len(weights)={len(weights)}` vs. \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                             \u001b[1;34mf\"`len(datasets)={len(datasets)}`.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Use the given `weights` as the probability of choosing the respective\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# input.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_skip_datasets_with_zero_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid `weights`. `weights` type must be either \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                          \u001b[1;34mf\"`tf.float32` or `tf.float64` but is \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                          \u001b[1;34mf\"{weights.dtype}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# The `stateless_multinomial()` op expects log-probabilities, as opposed\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# to weights.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logits\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# NOTE(mrry): We only specialize when `weights` is not a `Dataset`. When\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# it is a `Dataset`, it is possible that evaluating it has a side effect\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# the user depends on.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mdef\u001b[0m \u001b[0mselect_dataset_constant_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mgen_stateless_random_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateless_multinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mselector_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mRandomDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mselect_dataset_constant_logits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# Use each element of the given `weights` dataset as the probability of\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# choosing the respective input.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m#\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# The `stateless_multinomial()` op expects log-probabilities, as opposed\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;31m# to weights.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mlogits_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logits\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mdef\u001b[0m \u001b[0mselect_dataset_varying_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mgen_stateless_random_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateless_multinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mlogits_and_seeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[0mselector_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mlogits_and_seeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0mselect_dataset_varying_logits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m          \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_DirectedInterleaveDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselector_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                      \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m  \u001b[1;32mdef\u001b[0m \u001b[0mchoose_from_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                           \u001b[0mchoice_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                           \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Creates a dataset that deterministically chooses elements from `datasets`.\n",
      "\n",
      "    For example, given the following datasets:\n",
      "\n",
      "    ```python\n",
      "    datasets = [tf.data.Dataset.from_tensors(\"foo\").repeat(),\n",
      "                tf.data.Dataset.from_tensors(\"bar\").repeat(),\n",
      "                tf.data.Dataset.from_tensors(\"baz\").repeat()]\n",
      "\n",
      "    # Define a dataset containing `[0, 1, 2, 0, 1, 2, 0, 1, 2]`.\n",
      "    choice_dataset = tf.data.Dataset.range(3).repeat(3)\n",
      "\n",
      "    result = tf.data.Dataset.choose_from_datasets(datasets, choice_dataset)\n",
      "    ```\n",
      "\n",
      "    The elements of `result` will be:\n",
      "\n",
      "    ```\n",
      "    \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\"\n",
      "    ```\n",
      "\n",
      "    Args:\n",
      "      datasets: A non-empty list of `tf.data.Dataset` objects with compatible\n",
      "        structure.\n",
      "      choice_dataset: A `tf.data.Dataset` of scalar `tf.int64` tensors between\n",
      "        `0` and `len(datasets) - 1`.\n",
      "      stop_on_empty_dataset: If `True`, selection stops if it encounters an\n",
      "        empty dataset. If `False`, it skips empty datasets. It is recommended to\n",
      "        set it to `True`. Otherwise, the selected elements start off as the user\n",
      "        intends, but may change as input datasets become empty. This can be\n",
      "        difficult to detect since the dataset starts off looking correct.\n",
      "        Defaults to `True`.\n",
      "\n",
      "    Returns:\n",
      "      A dataset that interleaves elements from `datasets` according to the\n",
      "      values of `choice_dataset`.\n",
      "\n",
      "    Raises:\n",
      "      TypeError: If `datasets` or `choice_dataset` has the wrong type.\n",
      "      ValueError: If `datasets` is empty.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid `datasets`. `datasets` should not be empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid `choice_dataset`. `choice_dataset` should be a \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34mf\"`tf.data.Dataset` but is {type(choice_dataset)}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mare_compatible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                    \u001b[0mtensor_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m      \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid `choice_dataset`. Elements of `choice_dataset` \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34mf\"must be scalar `tf.int64` tensors but are \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                      \u001b[1;34mf\"{choice_dataset.element_spec}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Replicate the `choice_dataset` component so that each split makes choices\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# independently. This avoids the need for prohibitively expensive\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# cross-split coordination.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mchoice_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_apply_rewrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"replicate_on_split\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0m_DirectedInterleaveDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                                      \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\swaroop\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     DatasetV1, DatasetSource, UnaryDataset, _VariantDataset, ZipDataset, ConcatenateDataset, _DirectedInterleaveDataset, TFRecordDatasetV2, _PerDeviceGenerator, _ReincarnatedPerDeviceGenerator, ...\n"
     ]
    }
   ],
   "source": [
    "tf.data.Dataset??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6824 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: you can not direcly use index like a list  in the above data object. so you need to use the as_numpy_iterator()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops._NumpyIterator"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iterator = data.as_numpy_iterator()\n",
    "type(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[2.2100000e+02, 2.2300000e+02, 2.1200000e+02],\n",
       "          [2.2100000e+02, 2.2300000e+02, 2.1200000e+02],\n",
       "          [2.2031250e+02, 2.2231250e+02, 2.1131250e+02],\n",
       "          ...,\n",
       "          [2.2956250e+02, 2.3056250e+02, 2.2318750e+02],\n",
       "          [2.4606250e+02, 2.4687500e+02, 2.4106250e+02],\n",
       "          [2.5500000e+02, 2.5500000e+02, 2.5000000e+02]],\n",
       " \n",
       "         [[2.1937500e+02, 2.2137500e+02, 2.1037500e+02],\n",
       "          [2.1805469e+02, 2.2005469e+02, 2.0905469e+02],\n",
       "          [2.1650391e+02, 2.1850391e+02, 2.0750391e+02],\n",
       "          ...,\n",
       "          [2.2153906e+02, 2.2253906e+02, 2.1516406e+02],\n",
       "          [2.3575391e+02, 2.3671875e+02, 2.3075391e+02],\n",
       "          [2.4931250e+02, 2.5012500e+02, 2.4431250e+02]],\n",
       " \n",
       "         [[2.1762500e+02, 2.2031250e+02, 2.1068750e+02],\n",
       "          [2.1600000e+02, 2.1868750e+02, 2.0906250e+02],\n",
       "          [2.1519531e+02, 2.1788281e+02, 2.0731250e+02],\n",
       "          ...,\n",
       "          [2.1749609e+02, 2.1849609e+02, 2.1206641e+02],\n",
       "          [2.2851953e+02, 2.2951953e+02, 2.2351953e+02],\n",
       "          [2.4593750e+02, 2.4693750e+02, 2.4093750e+02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.0593750e+02, 2.0762500e+02, 1.9756250e+02],\n",
       "          [2.0954297e+02, 2.1123047e+02, 2.0116797e+02],\n",
       "          [2.1016016e+02, 2.1184766e+02, 2.0178516e+02],\n",
       "          ...,\n",
       "          [2.2630078e+02, 2.2698828e+02, 2.2223828e+02],\n",
       "          [2.3942969e+02, 2.3942969e+02, 2.3742969e+02],\n",
       "          [2.5293750e+02, 2.5293750e+02, 2.5093750e+02]],\n",
       " \n",
       "         [[2.0837500e+02, 2.0937500e+02, 2.0137500e+02],\n",
       "          [2.0888281e+02, 2.0988281e+02, 2.0188281e+02],\n",
       "          [2.0869922e+02, 2.0969922e+02, 2.0169922e+02],\n",
       "          ...,\n",
       "          [2.3719531e+02, 2.3788281e+02, 2.3313281e+02],\n",
       "          [2.5030859e+02, 2.5030859e+02, 2.4830859e+02],\n",
       "          [2.5462500e+02, 2.5462500e+02, 2.5262500e+02]],\n",
       " \n",
       "         [[2.1000000e+02, 2.1100000e+02, 2.0300000e+02],\n",
       "          [2.0918750e+02, 2.1018750e+02, 2.0218750e+02],\n",
       "          [2.1037500e+02, 2.1137500e+02, 2.0337500e+02],\n",
       "          ...,\n",
       "          [2.4400000e+02, 2.4468750e+02, 2.3993750e+02],\n",
       "          [2.5462500e+02, 2.5462500e+02, 2.5262500e+02],\n",
       "          [2.5300000e+02, 2.5300000e+02, 2.5100000e+02]]],\n",
       " \n",
       " \n",
       "        [[[1.2700000e+02, 9.0000000e+01, 6.3000000e+01],\n",
       "          [1.2537500e+02, 8.8375000e+01, 6.1375000e+01],\n",
       "          [1.2912500e+02, 9.2125000e+01, 6.5125000e+01],\n",
       "          ...,\n",
       "          [6.8812500e+01, 5.0812500e+01, 3.6812500e+01],\n",
       "          [6.3812500e+01, 4.5812500e+01, 3.1812500e+01],\n",
       "          [6.3000000e+01, 4.5000000e+01, 3.1000000e+01]],\n",
       " \n",
       "         [[1.2618750e+02, 8.9187500e+01, 6.2187500e+01],\n",
       "          [1.2456250e+02, 8.7562500e+01, 6.0562500e+01],\n",
       "          [1.2831250e+02, 9.1312500e+01, 6.4312500e+01],\n",
       "          ...,\n",
       "          [6.8558594e+01, 5.0558594e+01, 3.6558594e+01],\n",
       "          [6.3152344e+01, 4.5152344e+01, 3.1152344e+01],\n",
       "          [6.3000000e+01, 4.5000000e+01, 3.1000000e+01]],\n",
       " \n",
       "         [[1.2256250e+02, 8.5562500e+01, 5.8562500e+01],\n",
       "          [1.2149609e+02, 8.4496094e+01, 5.7496094e+01],\n",
       "          [1.2490234e+02, 8.7902344e+01, 6.0902344e+01],\n",
       "          ...,\n",
       "          [6.9187500e+01, 5.0500000e+01, 3.6500000e+01],\n",
       "          [6.3558594e+01, 4.4871094e+01, 3.0871094e+01],\n",
       "          [6.3000000e+01, 4.4312500e+01, 3.0312500e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[5.1000000e+01, 3.3000000e+01, 1.3000000e+01],\n",
       "          [5.1000000e+01, 3.3000000e+01, 1.3000000e+01],\n",
       "          [5.6500000e+01, 3.8500000e+01, 1.8500000e+01],\n",
       "          ...,\n",
       "          [5.5410156e+01, 3.8410156e+01, 2.8410156e+01],\n",
       "          [5.2246094e+01, 3.5246094e+01, 2.5246094e+01],\n",
       "          [5.2500000e+01, 3.5500000e+01, 2.5500000e+01]],\n",
       " \n",
       "         [[5.1187500e+01, 3.3187500e+01, 1.3187500e+01],\n",
       "          [5.1187500e+01, 3.3187500e+01, 1.3187500e+01],\n",
       "          [5.6558594e+01, 3.8558594e+01, 1.8558594e+01],\n",
       "          ...,\n",
       "          [5.9691406e+01, 4.2691406e+01, 3.2691406e+01],\n",
       "          [5.7000000e+01, 4.0000000e+01, 3.0000000e+01],\n",
       "          [5.7812500e+01, 4.0812500e+01, 3.0812500e+01]],\n",
       " \n",
       "         [[5.2000000e+01, 3.4000000e+01, 1.4000000e+01],\n",
       "          [5.2000000e+01, 3.4000000e+01, 1.4000000e+01],\n",
       "          [5.6812500e+01, 3.8812500e+01, 1.8812500e+01],\n",
       "          ...,\n",
       "          [5.9437500e+01, 4.2437500e+01, 3.2437500e+01],\n",
       "          [5.6187500e+01, 3.9187500e+01, 2.9187500e+01],\n",
       "          [5.7000000e+01, 4.0000000e+01, 3.0000000e+01]]],\n",
       " \n",
       " \n",
       "        [[[0.0000000e+00, 1.0000000e+00, 2.0000000e+00],\n",
       "          [0.0000000e+00, 1.0000000e+00, 3.7500000e-01],\n",
       "          [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 2.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 2.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 2.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 1.0000000e+00, 2.0000000e+00],\n",
       "          [0.0000000e+00, 1.6601562e+00, 1.0351562e+00],\n",
       "          [0.0000000e+00, 1.2539062e+00, 2.5390625e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 8.8281250e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 2.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 2.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 1.0000000e+00, 6.2500000e-01],\n",
       "          [0.0000000e+00, 1.2539062e+00, 3.7109375e-01],\n",
       "          [0.0000000e+00, 1.0976562e+00, 9.7656250e-02],\n",
       "          ...,\n",
       "          [0.0000000e+00, 2.1484375e-01, 1.9531250e-01],\n",
       "          [0.0000000e+00, 5.5859375e-01, 8.8281250e-01],\n",
       "          [0.0000000e+00, 0.0000000e+00, 2.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [7.8515625e-01, 1.9453125e+00, 9.7656250e-02],\n",
       "          [1.3164062e+00, 2.5390625e-01, 6.8750000e-01],\n",
       "          [2.6875000e+00, 0.0000000e+00, 2.3125000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [3.1250000e-01, 1.8164062e+00, 3.1250000e-01],\n",
       "          [1.1875000e+00, 8.8281250e-01, 1.4101562e+00],\n",
       "          [2.0000000e+00, 3.7500000e-01, 3.1875000e+00]],\n",
       " \n",
       "         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          ...,\n",
       "          [3.1250000e-01, 2.3750000e+00, 3.1250000e-01],\n",
       "          [1.1875000e+00, 1.1875000e+00, 1.5625000e+00],\n",
       "          [2.0000000e+00, 2.0000000e+00, 4.0000000e+00]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[2.5500000e+02, 2.5300000e+02, 2.5400000e+02],\n",
       "          [2.5337500e+02, 2.5300000e+02, 2.5318750e+02],\n",
       "          [2.5231250e+02, 2.5231250e+02, 2.5093750e+02],\n",
       "          ...,\n",
       "          [2.5500000e+02, 2.5500000e+02, 2.5000000e+02],\n",
       "          [2.5443750e+02, 2.5443750e+02, 2.4887500e+02],\n",
       "          [2.5200000e+02, 2.5200000e+02, 2.4400000e+02]],\n",
       " \n",
       "         [[2.5256250e+02, 2.5056250e+02, 2.5156250e+02],\n",
       "          [2.5357812e+02, 2.5320312e+02, 2.5339062e+02],\n",
       "          [2.5368359e+02, 2.5424219e+02, 2.5286719e+02],\n",
       "          ...,\n",
       "          [2.5444141e+02, 2.5474609e+02, 2.4974609e+02],\n",
       "          [2.5474219e+02, 2.5423438e+02, 2.4867188e+02],\n",
       "          [2.5362500e+02, 2.5443750e+02, 2.4643750e+02]],\n",
       " \n",
       "         [[2.5337500e+02, 2.5275000e+02, 2.5168750e+02],\n",
       "          [2.5388281e+02, 2.5432422e+02, 2.5300781e+02],\n",
       "          [2.5400000e+02, 2.5490234e+02, 2.5309766e+02],\n",
       "          ...,\n",
       "          [2.5298047e+02, 2.5425781e+02, 2.4925781e+02],\n",
       "          [2.5244922e+02, 2.5307031e+02, 2.4776562e+02],\n",
       "          [2.5331250e+02, 2.5500000e+02, 2.4837500e+02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.5331250e+02, 2.5368750e+02, 2.4962500e+02],\n",
       "          [2.5361719e+02, 2.5450000e+02, 2.4967578e+02],\n",
       "          [2.5321484e+02, 2.5490234e+02, 2.4990234e+02],\n",
       "          ...,\n",
       "          [2.5400000e+02, 2.5500000e+02, 2.4990234e+02],\n",
       "          [2.5412891e+02, 2.5500000e+02, 2.4957031e+02],\n",
       "          [2.5468750e+02, 2.5500000e+02, 2.4906250e+02]],\n",
       " \n",
       "         [[2.5400000e+02, 2.5300000e+02, 2.5100000e+02],\n",
       "          [2.5318750e+02, 2.5381250e+02, 2.4937500e+02],\n",
       "          [2.5312891e+02, 2.5468750e+02, 2.4968750e+02],\n",
       "          ...,\n",
       "          [2.5412891e+02, 2.5500000e+02, 2.4968750e+02],\n",
       "          [2.5400000e+02, 2.5500000e+02, 2.4862500e+02],\n",
       "          [2.5400000e+02, 2.5500000e+02, 2.4700000e+02]],\n",
       " \n",
       "         [[2.5400000e+02, 2.5300000e+02, 2.5100000e+02],\n",
       "          [2.5318750e+02, 2.5381250e+02, 2.4937500e+02],\n",
       "          [2.5368750e+02, 2.5468750e+02, 2.4968750e+02],\n",
       "          ...,\n",
       "          [2.5468750e+02, 2.5500000e+02, 2.4968750e+02],\n",
       "          [2.5400000e+02, 2.5500000e+02, 2.4862500e+02],\n",
       "          [2.5400000e+02, 2.5500000e+02, 2.4700000e+02]]],\n",
       " \n",
       " \n",
       "        [[[2.4400000e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          [2.4400000e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          [2.4331250e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          ...,\n",
       "          [2.3931250e+02, 2.4275000e+02, 2.5000000e+02],\n",
       "          [2.4018750e+02, 2.3981250e+02, 2.5000000e+02],\n",
       "          [2.4100000e+02, 2.3900000e+02, 2.5000000e+02]],\n",
       " \n",
       "         [[2.4400000e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          [2.4400000e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          [2.4331250e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          ...,\n",
       "          [2.3905859e+02, 2.4249609e+02, 2.4923828e+02],\n",
       "          [2.3891797e+02, 2.3884766e+02, 2.4725781e+02],\n",
       "          [2.3775000e+02, 2.3737500e+02, 2.4593750e+02]],\n",
       " \n",
       "         [[2.4400000e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          [2.4400000e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          [2.4331250e+02, 2.4800000e+02, 2.5100000e+02],\n",
       "          ...,\n",
       "          [2.3693750e+02, 2.4007422e+02, 2.4558203e+02],\n",
       "          [2.3682031e+02, 2.3888281e+02, 2.4482031e+02],\n",
       "          [2.3631250e+02, 2.3837500e+02, 2.4431250e+02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.3962500e+02, 2.4268750e+02, 2.4400000e+02],\n",
       "          [2.3962500e+02, 2.4268750e+02, 2.4400000e+02],\n",
       "          [2.4078516e+02, 2.4268750e+02, 2.4262500e+02],\n",
       "          ...,\n",
       "          [2.2941016e+02, 2.3872266e+02, 2.3834766e+02],\n",
       "          [2.2893750e+02, 2.3893750e+02, 2.3993750e+02],\n",
       "          [2.2893750e+02, 2.3893750e+02, 2.3993750e+02]],\n",
       " \n",
       "         [[2.4100000e+02, 2.4200000e+02, 2.4400000e+02],\n",
       "          [2.4100000e+02, 2.4200000e+02, 2.4400000e+02],\n",
       "          [2.4168750e+02, 2.4200000e+02, 2.4262500e+02],\n",
       "          ...,\n",
       "          [2.3111719e+02, 2.4042969e+02, 2.4005469e+02],\n",
       "          [2.3141016e+02, 2.4141016e+02, 2.4241016e+02],\n",
       "          [2.3156250e+02, 2.4156250e+02, 2.4256250e+02]],\n",
       " \n",
       "         [[2.4100000e+02, 2.4200000e+02, 2.4400000e+02],\n",
       "          [2.4100000e+02, 2.4200000e+02, 2.4400000e+02],\n",
       "          [2.4168750e+02, 2.4200000e+02, 2.4262500e+02],\n",
       "          ...,\n",
       "          [2.3162500e+02, 2.4093750e+02, 2.4056250e+02],\n",
       "          [2.3318750e+02, 2.4318750e+02, 2.4418750e+02],\n",
       "          [2.3400000e+02, 2.4400000e+02, 2.4500000e+02]]],\n",
       " \n",
       " \n",
       "        [[[2.5500000e+02, 2.5500000e+02, 2.5500000e+02],\n",
       "          [2.4768750e+02, 2.4768750e+02, 2.4768750e+02],\n",
       "          [2.5012500e+02, 2.5012500e+02, 2.5012500e+02],\n",
       "          ...,\n",
       "          [9.0500000e+01, 9.0500000e+01, 9.0500000e+01],\n",
       "          [1.3650000e+02, 1.3650000e+02, 1.3650000e+02],\n",
       "          [1.6900000e+02, 1.6900000e+02, 1.6900000e+02]],\n",
       " \n",
       "         [[2.4687500e+02, 2.4687500e+02, 2.4687500e+02],\n",
       "          [2.5012500e+02, 2.5012500e+02, 2.5012500e+02],\n",
       "          [2.4773828e+02, 2.4773828e+02, 2.4773828e+02],\n",
       "          ...,\n",
       "          [8.5371094e+01, 8.5371094e+01, 8.5371094e+01],\n",
       "          [1.3111719e+02, 1.3111719e+02, 1.3111719e+02],\n",
       "          [1.6493750e+02, 1.6493750e+02, 1.6493750e+02]],\n",
       " \n",
       "         [[2.5187500e+02, 2.5187500e+02, 2.5187500e+02],\n",
       "          [2.4750781e+02, 2.4750781e+02, 2.4750781e+02],\n",
       "          [2.2703516e+02, 2.2703516e+02, 2.2703516e+02],\n",
       "          ...,\n",
       "          [9.4757812e+01, 9.4757812e+01, 9.4757812e+01],\n",
       "          [1.4053125e+02, 1.4053125e+02, 1.4053125e+02],\n",
       "          [1.7912500e+02, 1.7912500e+02, 1.7912500e+02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.5500000e+02, 2.5500000e+02, 2.5500000e+02],\n",
       "          [2.5388281e+02, 2.5388281e+02, 2.5388281e+02],\n",
       "          [2.3802734e+02, 2.3802734e+02, 2.3802734e+02],\n",
       "          ...,\n",
       "          [2.4495703e+02, 2.4495703e+02, 2.4495703e+02],\n",
       "          [2.4547656e+02, 2.4547656e+02, 2.4547656e+02],\n",
       "          [2.4456250e+02, 2.4456250e+02, 2.4456250e+02]],\n",
       " \n",
       "         [[2.5500000e+02, 2.5500000e+02, 2.5500000e+02],\n",
       "          [2.5500000e+02, 2.5500000e+02, 2.5500000e+02],\n",
       "          [2.5461328e+02, 2.5461328e+02, 2.5461328e+02],\n",
       "          ...,\n",
       "          [2.4239453e+02, 2.4239453e+02, 2.4239453e+02],\n",
       "          [2.3389062e+02, 2.3389062e+02, 2.3389062e+02],\n",
       "          [2.2068750e+02, 2.2068750e+02, 2.2068750e+02]],\n",
       " \n",
       "         [[2.5500000e+02, 2.5500000e+02, 2.5500000e+02],\n",
       "          [2.5500000e+02, 2.5500000e+02, 2.5500000e+02],\n",
       "          [2.5293750e+02, 2.5293750e+02, 2.5293750e+02],\n",
       "          ...,\n",
       "          [2.2812500e+02, 2.2812500e+02, 2.2812500e+02],\n",
       "          [1.9225000e+02, 1.9225000e+02, 1.9225000e+02],\n",
       "          [1.5000000e+02, 1.5000000e+02, 1.5000000e+02]]]], dtype=float32),\n",
       " array([1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_iterator.next()\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 256, 256, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(batch))  # this is 2 coz there are the images and the labels.\n",
    "batch[0].shape\n",
    "# therefore each batch has 32 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path, filename):\n",
    "    img = cv.imread(os.path.join(path, filename))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [134], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mloc[:, \u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mhead(\u001b[39m16\u001b[39m):\n\u001b[0;32m      5\u001b[0m     img  \u001b[39m=\u001b[39m get_image(path, image)\n\u001b[1;32m----> 6\u001b[0m     axis[count]\u001b[39m.\u001b[39mimshow(\u001b[39mint\u001b[39;49m(img))\n\u001b[0;32m      7\u001b[0m     count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x4000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './data/train/'\n",
    "fig, axis = plt.subplots(ncols = 4, figsize = (40, 40))\n",
    "count = 0\n",
    "for image in df.loc[:, 'filename'].head(16):\n",
    "    img  = get_image(path, image)\n",
    "    axis[count].imshow(int(img))\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "path = './data/train/'\n",
    "print(get_image(path, df.loc[:, 'label'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Image_1.jpg'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'filename'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/train/'\n",
    "img = cv.imread(os.path.join(path, 'Image_1.jpg'))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['images'] = [get_image(path ,img) for img in df.loc[:, 'filename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img_list \u001b[39m=\u001b[39m  [get_image(path ,img) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mloc[:, \u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      2\u001b[0m \u001b[39mlen\u001b[39m(img_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "img_list =  [get_image(path ,img) for img in df.loc[:, 'filename']]\n",
    "len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>face_on_card</th>\n",
       "      <th>number_on_card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[244, 244, 244], [244, 244, 244], [248, 248,...</td>\n",
       "      <td>clubs</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[247, 255, 253], [247, 255, 254], [250, 254,...</td>\n",
       "      <td>hearts</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[248, 255, 252], [248, 255, 252], [248, 255,...</td>\n",
       "      <td>diamonds</td>\n",
       "      <td>seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[251, 249, 249], [251, 249, 249], [250, 248,...</td>\n",
       "      <td>spades</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[255, 255, 255], [250, 248, 248], [244, 242,...</td>\n",
       "      <td>spades</td>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              images face_on_card  \\\n",
       "0  [[[244, 244, 244], [244, 244, 244], [248, 248,...        clubs   \n",
       "1  [[[247, 255, 253], [247, 255, 254], [250, 254,...       hearts   \n",
       "2  [[[248, 255, 252], [248, 255, 252], [248, 255,...     diamonds   \n",
       "3  [[[251, 249, 249], [251, 249, 249], [250, 248,...       spades   \n",
       "4  [[[255, 255, 255], [250, 248, 248], [244, 242,...       spades   \n",
       "\n",
       "  number_on_card  \n",
       "0            six  \n",
       "1          queen  \n",
       "2          seven  \n",
       "3            six  \n",
       "4          eight  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "final_df  = df.loc[:, ['images', 'face_on_card', 'number_on_card']]\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalising the image matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['images'] = df['images'].map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "card face classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['face_encoded'] = le.fit_transform(df['face_on_card'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numbrt_encoded'] = le.fit_transform(df['number_on_card'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>number_on_card</th>\n",
       "      <th>face_on_card</th>\n",
       "      <th>images</th>\n",
       "      <th>face_encoded</th>\n",
       "      <th>numbrt_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>six of clubs</td>\n",
       "      <td>six</td>\n",
       "      <td>clubs</td>\n",
       "      <td>[[[0.9568627450980393, 0.9568627450980393, 0.9...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>queen of hearts</td>\n",
       "      <td>queen</td>\n",
       "      <td>hearts</td>\n",
       "      <td>[[[0.9686274509803922, 1.0, 0.9921568627450981...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>seven of diamonds</td>\n",
       "      <td>seven</td>\n",
       "      <td>diamonds</td>\n",
       "      <td>[[[0.9725490196078431, 1.0, 0.9882352941176471...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>six of spades</td>\n",
       "      <td>six</td>\n",
       "      <td>spades</td>\n",
       "      <td>[[[0.984313725490196, 0.9764705882352941, 0.97...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>eight of spades</td>\n",
       "      <td>eight</td>\n",
       "      <td>spades</td>\n",
       "      <td>[[[1.0, 1.0, 1.0], [0.9803921568627451, 0.9725...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename              label number_on_card face_on_card  \\\n",
       "0  Image_1.jpg       six of clubs            six        clubs   \n",
       "1  Image_2.jpg    queen of hearts          queen       hearts   \n",
       "2  Image_3.jpg  seven of diamonds          seven     diamonds   \n",
       "3  Image_4.jpg      six of spades            six       spades   \n",
       "4  Image_5.jpg    eight of spades          eight       spades   \n",
       "\n",
       "                                              images  face_encoded  \\\n",
       "0  [[[0.9568627450980393, 0.9568627450980393, 0.9...             0   \n",
       "1  [[[0.9686274509803922, 1.0, 0.9921568627450981...             2   \n",
       "2  [[[0.9725490196078431, 1.0, 0.9882352941176471...             1   \n",
       "3  [[[0.984313725490196, 0.9764705882352941, 0.97...             4   \n",
       "4  [[[1.0, 1.0, 1.0], [0.9803921568627451, 0.9725...             4   \n",
       "\n",
       "   numbrt_encoded  \n",
       "0              10  \n",
       "1               8  \n",
       "2               9  \n",
       "3              10  \n",
       "4               1  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'label', 'number_on_card', 'face_on_card', 'images',\n",
       "       'face_encoded', 'numbrt_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding which LABEL IS ASSIGNEDT TO WHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_on_card</th>\n",
       "      <th>face_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clubs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>diamonds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>hearts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>joker</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>spades</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     face_on_card  face_encoded\n",
       "0           clubs             0\n",
       "3416     diamonds             1\n",
       "4532       hearts             2\n",
       "2671        joker             3\n",
       "4147       spades             4"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_face = df.loc[:, ['face_on_card', 'face_encoded']]\n",
    "df_label_face.sort_values(by = 'face_encoded').drop_duplicates(subset = ['face_on_card'], keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_number = df.loc[:, ['face_on_card', 'numbrt_encoded']]\n",
    "df_label_number.sort_values(by = 'numbrt_encoded').drop_duplicates(subset = ['number_on_card'], keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['clubs', 'hearts', 'diamonds', ..., 'clubs', 'clubs', 'clubs'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['face_on_card'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4776,)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940     [[[0.9921568627450981, 0.996078431372549, 0.98...\n",
       "210     [[[1.0, 1.0, 1.0], [0.996078431372549, 0.99607...\n",
       "1806    [[[0.45098039215686275, 0.38823529411764707, 0...\n",
       "4065    [[[0.8509803921568627, 0.8588235294117647, 0.8...\n",
       "4297    [[[0.9529411764705882, 0.9372549019607843, 0.9...\n",
       "                              ...                        \n",
       "677     [[[0.9176470588235294, 0.9058823529411765, 0.8...\n",
       "1941    [[[0.9921568627450981, 0.9921568627450981, 0.9...\n",
       "46      [[[0.09411764705882353, 0.09411764705882353, 0...\n",
       "2317    [[[0.8941176470588236, 0.9176470588235294, 0.9...\n",
       "1206    [[[1.0, 0.996078431372549, 0.996078431372549],...\n",
       "Name: images, Length: 3820, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df['images'], df['face_encoded'], test_size = 0.2)\n",
    "train_x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3820,)\n",
      "(3820,)\n",
      "(956,)\n",
      "(956,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_list  = train_x.to_list()\n",
    "train_y_list = train_y.to_list()\n",
    "test_x_list = test_x.to_list()\n",
    "test_y_list = test_y.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key of type tuple not found and not a MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [196], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m      2\u001b[0m idx \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(train_x))\n\u001b[1;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39mimshow(train_x[idx, :])\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m   1005\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[1;32m-> 1007\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\series.py:1022\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1018\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndexing a Series with DataFrame is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported, use the appropriate DataFrame column\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1021\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m-> 1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_values_tuple(key)\n\u001b[0;32m   1024\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key):\n\u001b[0;32m   1025\u001b[0m     \u001b[39m# e.g. scalars that aren't recognized by lib.is_scalar, GH#32684\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[key]\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\series.py:1060\u001b[0m, in \u001b[0;36mSeries._get_values_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m   1059\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m-> 1060\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mkey of type tuple not found and not a MultiIndex\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[39m# If key is contained, would have returned by now\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m indexer, new_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc_level(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(train_x))\n",
    "plt.imshow(train_x[idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32,32,3)),\n",
    "        layers.Dense(3000, activation='relu'),\n",
    "        layers.Dense(1000, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')    \n",
    "    ])\n",
    "\n",
    "ann.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "ann.fit(train_x, train_y, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation = \"relu\",input_shape =(224,224,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(32, (3,3), activation = \"relu\"), \n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation = \"relu\"),\n",
    "    Dense(4, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [193], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(train_x, dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mint64)\n\u001b[0;32m      3\u001b[0m y_train_list\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconvert_to_tensor(train_y, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint64)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "x_train_list = tf.convert_to_tensor(train_x, dtype=tf.int64)\n",
    "\n",
    "y_train_list=tf.convert_to_tensor(train_y, dtype=tf.int64) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_Crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [189], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_x_list, train_y_list, epochs \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\data_adapter.py:1083\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1080\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m   1081\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m-> 1083\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1084\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1085\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(_type_name(x), _type_name(y))\n\u001b[0;32m   1086\u001b[0m     )\n\u001b[0;32m   1087\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1089\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[0;32m   1092\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "model.fit(train_x_list, train_y_list, epochs = 5, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0975b8fee8824b268fe468d6c313308a0d051291cfba5702c863b99bfd677d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
